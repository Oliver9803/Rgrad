{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=1\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=1\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=1\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=1\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "from scipy.sparse import csr_matrix\n",
    "from tensorly.tenalg import contract\n",
    "import torch\n",
    "from multiprocessing import Pool\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_to_tensor(core, p_vec):\n",
    "    d = int(len(core)-1)/2\n",
    "    if d==2:\n",
    "        result = contract(contract(contract(contract(core[0], 2, core[1], 0), 3, core[2], 0), 3, core[3], 0), 4, core[4], 0)\n",
    "    elif d==3:\n",
    "        result = contract(contract(contract(contract(contract(contract(core[0], 2, core[1], 0), 3, core[2], 0), 4, core[3], 0), 4,\n",
    "                          core[4], 0), 5, core[5], 0), 6, core[6], 0)\n",
    "    elif d==4:\n",
    "        result = contract(contract(contract(contract(contract(contract(contract(contract(core[0], 2, core[1], 0), 3, core[2], 0), 4, core[3], 0), 5,\n",
    "                              core[4], 0), 5, core[5], 0), 6, core[6], 0), 7, core[7], 0), 8, core[8], 0)\n",
    "    return result.reshape(p_vec, order=\"F\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_to_tensor1(core, p_vec):\n",
    "    result = contract(contract(contract(contract(contract(core[0], 2, core[1], 0), 3, core[2], 0), 3, core[3], 0), 4,\n",
    "                          core[4], 0), 5, core[5], 0)\n",
    "    return result.reshape(p_vec, order=\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appproj(A,mtl_rank):\n",
    "    p_vec = A.shape\n",
    "    p = np.prod(p_vec)\n",
    "    d = len(p_vec)\n",
    "    a0 = 1\n",
    "    for i in range(d-1):\n",
    "        a0 = a0 * p_vec[i]\n",
    "        A = A.reshape(a0,int(p/a0),order=\"F\")\n",
    "        U,S,V = torch.svd(torch.tensor(A))\n",
    "        U=U.numpy()\n",
    "        S=S.numpy()\n",
    "        V=V.numpy()\n",
    "        A=U[:,:mtl_rank[i]]@np.diag(S[:mtl_rank[i]])@(V[:,:mtl_rank[i]]).T\n",
    "        A=A.reshape(p_vec,order=\"F\")\n",
    "        \n",
    "    A = A.reshape(p_vec,order=\"F\")\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def PGD(Y, X, trueA, p_vec1, p_vec, mtl_rank, eta, max_iter, tol):\n",
    "    #p2_vec = size_of_tensor * 2\n",
    "    p1, N = Y.shape\n",
    "    p, N = X.shape\n",
    "    Amat =np.zeros((p1,p))##\n",
    "    #Amat = trueA\n",
    "    #A_list = [None] * max_iter\n",
    "    chg_list = [None] * max_iter\n",
    "    est_list = [None] * max_iter\n",
    "    n = 0\n",
    "    chg = np.inf\n",
    "    while n < max_iter and chg > tol:\n",
    "        #print(\"b\")\n",
    "        start = time.time()\n",
    "        g_k = Amat - (eta*2/(N-1))*(Amat@X-Y)@np.transpose(X)\n",
    "        #g_k = g_k.reshape([p,p_vec[2],p_vec[1],p_vec[0]])\n",
    "        g_k = g_k.reshape(p_vec1+p_vec,order=\"F\")\n",
    "        #g_k = TTOI(g_k, mtl_rank, iter=10, tol=1e-3)[-1]\n",
    "        #A_list[n] = g_k\n",
    "        g_k = appproj(g_k,mtl_rank)\n",
    "        #g_k = g_k.reshape([p,p_vec[2],p_vec[1],p_vec[0]], order=\"F\")\n",
    "        g_k = g_k.reshape(p1,p,order=\"F\")\n",
    "        #g_k = g_k.reshape(p, p, order=\"F\")\n",
    "        chg = np.linalg.norm(g_k-Amat, \"fro\")\n",
    "        chg_list[n] = chg\n",
    "        est_list[n] = np.linalg.norm(g_k-trueA, \"fro\")\n",
    "        if chg>10:\n",
    "            break\n",
    "        end=time.time()\n",
    "        #print(end-start)\n",
    "        #print(chg)\n",
    "        #print(np.linalg.norm(g_k-trueA, \"fro\"))\n",
    "        #print(n)\n",
    "        Amat = g_k\n",
    "        n = n+1\n",
    "\n",
    "    return ([x for x in chg_list if x is not None],[x for x in est_list if x is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d1(ind):\n",
    "    # Step 1 generate G and sigma\n",
    "    # d=3 p1=p2=p3=10 r=(1,2,2,2,2,2,1)\n",
    "    # norm(A)=norm(sigma)=5\n",
    "    # T = [1000,1200,1400,1600,2000]\n",
    "    p_vec=[3,3,3]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[3,3]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    N=600\n",
    "    scipy.random.seed()\n",
    "    mtl_rank = [1,1,1,1,1,1]\n",
    "    global G1; global G2; global G3; global sigma; global G4; global G5; global G6;\n",
    "    global A_ts; global A_mat\n",
    "    G1 = np.linalg.svd(np.random.normal(0,1,p_vec1[0]*p_vec1[0]).reshape(p_vec1[0],p_vec1[0]))[0][:,0:mtl_rank[1]].reshape(mtl_rank[0],p_vec1[0],mtl_rank[1],order=\"F\")\n",
    "    G2 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[1]*mtl_rank[1])).reshape(p_vec1[1]*mtl_rank[1],p_vec1[1]*mtl_rank[1]))[0][:,0:mtl_rank[2]].reshape(mtl_rank[1],p_vec1[1],mtl_rank[2],order=\"F\")\n",
    "    #G3 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[2]*mtl_rank[2])).reshape(p_vec1[2]*mtl_rank[2],p_vec1[2]*mtl_rank[2]))[0][:,0:mtl_rank[3]].reshape(mtl_rank[2],p_vec1[2],mtl_rank[3],order=\"F\")\n",
    "    sigma = np.diag(np.random.normal(0,1,mtl_rank[2]))\n",
    "    sigma = 5*sigma/np.linalg.norm(sigma)\n",
    "    G4 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[0]*mtl_rank[3])).reshape(p_vec[0]*mtl_rank[3],p_vec[0]*mtl_rank[3]))[2][0:mtl_rank[2],:].reshape(mtl_rank[2],p_vec[0],mtl_rank[3],order=\"F\")\n",
    "    G5 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[1]*mtl_rank[4])).reshape(p_vec[1]*mtl_rank[4],p_vec[1]*mtl_rank[4]))[2][0:mtl_rank[3],:].reshape(mtl_rank[3],p_vec[1],mtl_rank[4],order=\"F\")\n",
    "    G6 = np.linalg.svd(np.random.normal(0,1,p_vec[2]*p_vec[2]).reshape(p_vec[2],p_vec[2]))[2][0:mtl_rank[4],:].reshape(mtl_rank[4],p_vec[2],mtl_rank[5],order=\"F\")\n",
    "    A_ts = core_to_tensor1([G1,G2,sigma,G4,G5,G6], p_vec1+p_vec)\n",
    "    #A_ts = TTOI(A_ts, [2,2,2,2,2], iter=4, tol=1e-3)[-1]\n",
    "    #A_mat = A_ts.reshape(p, p, order=\"F\")###\n",
    "    A_mat = A_ts.reshape(p1, p, order=\"F\")\n",
    "    #print(np.linalg.norm(A_mat,\"fro\"))\n",
    "    #A_mat = A_mat.reshape(p,p)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "\n",
    "        \n",
    "    result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,1,1,1], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.10492308603958213,\n",
       "  0.1027125026507236,\n",
       "  0.10054809349508809,\n",
       "  0.09842958468724554,\n",
       "  0.09635621121603669,\n",
       "  0.09432707749323617,\n",
       "  0.09234126074712365,\n",
       "  0.0903978404444434,\n",
       "  0.08849590825723105,\n",
       "  0.08663457183248871,\n",
       "  0.08481295626286087,\n",
       "  0.08303020460016258,\n",
       "  0.08128547793400041,\n",
       "  0.07957795525958115,\n",
       "  0.07790683323862369,\n",
       "  0.07627132590490011,\n",
       "  0.07467066434122993,\n",
       "  0.0731040963425955,\n",
       "  0.0715708860737223,\n",
       "  0.07007031372593803,\n",
       "  0.06860167517620427,\n",
       "  0.06716428165007539,\n",
       "  0.06575745938967885,\n",
       "  0.06438054932731646,\n",
       "  0.06303290676511562,\n",
       "  0.06171390106087401,\n",
       "  0.060422915320333385,\n",
       "  0.05915934609570662,\n",
       "  0.0579226030906249,\n",
       "  0.05671210887137008,\n",
       "  0.05552729858428387,\n",
       "  0.054367619679306214,\n",
       "  0.05323253163959297,\n",
       "  0.05212150571693152,\n",
       "  0.05103402467306993,\n",
       "  0.04996958252666876,\n",
       "  0.04892768430582481,\n",
       "  0.0479078458060626,\n",
       "  0.046909593353693275,\n",
       "  0.045932463574341886,\n",
       "  0.04497600316662286,\n",
       "  0.04403976868084134,\n",
       "  0.04312332630254092,\n",
       "  0.04222625164088766,\n",
       "  0.04134812952170929,\n",
       "  0.04048855378508906,\n",
       "  0.03964712708752236,\n",
       "  0.03882346070838737,\n",
       "  0.03801717436069586,\n",
       "  0.0372278960060673,\n",
       "  0.03645526167379556,\n",
       "  0.03569891528387483,\n",
       "  0.034958508474026845,\n",
       "  0.03423370043045374,\n",
       "  0.03352415772243336,\n",
       "  0.03282955414048388,\n",
       "  0.032149570538208806,\n",
       "  0.03148389467754223,\n",
       "  0.03083222107747145,\n",
       "  0.030194250866104284,\n",
       "  0.029569691635969408,\n",
       "  0.02895825730262153,\n",
       "  0.028359667966155917,\n",
       "  0.027773649776059985,\n",
       "  0.027199934798819693,\n",
       "  0.02663826088861394,\n",
       "  0.026088371560706404,\n",
       "  0.025550015867814177,\n",
       "  0.025022948279059123,\n",
       "  0.02450692856165652,\n",
       "  0.024001721665201644,\n",
       "  0.023507097608546253,\n",
       "  0.02302283136907203,\n",
       "  0.022548702774541334,\n",
       "  0.02208449639723416,\n",
       "  0.02163000145042261,\n",
       "  0.02118501168723516,\n",
       "  0.020749325301576523,\n",
       "  0.020322744831378775,\n",
       "  0.01990507706393564,\n",
       "  0.01949613294328493,\n",
       "  0.01909572747968593,\n",
       "  0.018703679661059885,\n",
       "  0.01831981236639967,\n",
       "  0.017943952281056576,\n",
       "  0.017575929813918395,\n",
       "  0.017215579016395043,\n",
       "  0.016862737503198274,\n",
       "  0.01651724637485614,\n",
       "  0.016178950141915175,\n",
       "  0.01584769665086685,\n",
       "  0.015523337011592371,\n",
       "  0.01520572552655301,\n",
       "  0.014894719621389541,\n",
       "  0.014590179777137925,\n",
       "  0.0142919694639051,\n",
       "  0.013999955075988002,\n",
       "  0.013714005868463565,\n",
       "  0.013433993895077224,\n",
       "  0.013159793947626897,\n",
       "  0.012891283496546209,\n",
       "  0.012628342632870208,\n",
       "  0.012370854011477049,\n",
       "  0.012118702795491031,\n",
       "  0.011871776602017424,\n",
       "  0.011629965448984033,\n",
       "  0.011393161703162687,\n",
       "  0.01116126002938978,\n",
       "  0.010934157340773944,\n",
       "  0.010711752750141426,\n",
       "  0.01049394752242432,\n",
       "  0.010280645028173744,\n",
       "  0.010071750698006894,\n",
       "  0.009867171978158205,\n",
       "  0.009666818286892713,\n",
       "  0.009470600971943563,\n",
       "  0.00927843326884308,\n",
       "  0.009090230260217784,\n",
       "  0.008905908835868016,\n",
       "  0.008725387653858538,\n",
       "  0.008548587102313342,\n",
       "  0.008375429262180515,\n",
       "  0.008205837870723216,\n",
       "  0.008039738285783889,\n",
       "  0.007877057450959433,\n",
       "  0.0077177238613747945,\n",
       "  0.007561667530329476,\n",
       "  0.007408819956564407,\n",
       "  0.007259114092375042,\n",
       "  0.007112484312275734,\n",
       "  0.006968866382423339,\n",
       "  0.006828197430722615,\n",
       "  0.006690415917533115,\n",
       "  0.0065554616070576865,\n",
       "  0.006423275539295646,\n",
       "  0.006293800002676564,\n",
       "  0.006166978507241023,\n",
       "  0.006042755758412719,\n",
       "  0.005921077631356921,\n",
       "  0.005801891145899162,\n",
       "  0.005685144441930769,\n",
       "  0.005570786755452112,\n",
       "  0.005458768395009634,\n",
       "  0.005349040718777188,\n",
       "  0.0052415561120416464,\n",
       "  0.00513626796518776,\n",
       "  0.005033130652224919,\n",
       "  0.004932099509661341,\n",
       "  0.004833130815974403,\n",
       "  0.004736181771441744,\n",
       "  0.004641210478392027,\n",
       "  0.00454817592198683,\n",
       "  0.004457037951276362,\n",
       "  0.004367757260773379,\n",
       "  0.004280295372403625,\n",
       "  0.004194614617821741,\n",
       "  0.004110678121129738,\n",
       "  0.004028449781947315,\n",
       "  0.003947894258881988,\n",
       "  0.0038689769533189334,\n",
       "  0.0037916639936035807,\n",
       "  0.003715922219554734,\n",
       "  0.0036417191672309555,\n",
       "  0.0035690230541834014,\n",
       "  0.0034978027648952226,\n",
       "  0.003428027836572728,\n",
       "  0.00335966844525442,\n",
       "  0.003292695392254603,\n",
       "  0.003227080090801052,\n",
       "  0.0031627945530604256,\n",
       "  0.003099811377386433,\n",
       "  0.003038103735850596,\n",
       "  0.0029776453620770503,\n",
       "  0.0029184105393068997,\n",
       "  0.002860374088687064,\n",
       "  0.002803511357896268,\n",
       "  0.0027477982099595364,\n",
       "  0.002693211012275279,\n",
       "  0.0026397266259879514,\n",
       "  0.002587322395439139,\n",
       "  0.0025359761379614956,\n",
       "  0.0024856661338850243,\n",
       "  0.0024363711166450327,\n",
       "  0.002388070263271179,\n",
       "  0.0023407431849581297,\n",
       "  0.0022943699178308258,\n",
       "  0.002248930914043737,\n",
       "  0.002204407032890836,\n",
       "  0.002160779532288765,\n",
       "  0.0021180300602294828,\n",
       "  0.002076140646640793,\n",
       "  0.0020350936952694084,\n",
       "  0.0019948719757825755,\n",
       "  0.0019554586160480903,\n",
       "  0.001916837094574543,\n",
       "  0.0018789912331370734,\n",
       "  0.0018419051894548602,\n",
       "  0.001805563450199071,\n",
       "  0.0017699508239998247,\n",
       "  0.0017350524346918408,\n",
       "  0.001700853714632021,\n",
       "  0.0016673403982525319,\n",
       "  0.001634498515631208,\n",
       "  0.0016023143863707527,\n",
       "  0.0015707746133734502,\n",
       "  0.0015398660770165355,\n",
       "  0.0015095759291840875,\n",
       "  0.0014798915876762003,\n",
       "  0.0014508007305487499,\n",
       "  0.0014222912906460335,\n",
       "  0.001394351450293591,\n",
       "  0.001366969636012573,\n",
       "  0.0013401345134116001,\n",
       "  0.001313834982176757,\n",
       "  0.0012880601711600808,\n",
       "  0.0012627994335451017,\n",
       "  0.001238042342172003,\n",
       "  0.0012137786849371359,\n",
       "  0.0011899984602549065,\n",
       "  0.0011666918726921823,\n",
       "  0.0011438493285972926,\n",
       "  0.001121461431947435,\n",
       "  0.0010995189801216582,\n",
       "  0.0010780129599400605,\n",
       "  0.0010569345436610069,\n",
       "  0.0010362750850939839,\n",
       "  0.0010160261158553771,\n",
       "  0.0009961793415624869,\n",
       "  0.0009767266383105477,\n",
       "  0.0009576600490231528,\n",
       "  0.0009389717800353455,\n",
       "  0.0009206541976083367,\n",
       "  0.0009026998246882161,\n",
       "  0.0008851013375544461,\n",
       "  0.000867851562671992,\n",
       "  0.0008509434735405472,\n",
       "  0.0008343701876523064,\n",
       "  0.0008181249634489848,\n",
       "  0.0008022011974355222,\n",
       "  0.0007865924213162966,\n",
       "  0.0007712922991020983,\n",
       "  0.0007562946244419617,\n",
       "  0.0007415933178839728,\n",
       "  0.0007271824242442573,\n",
       "  0.000713056110066532,\n",
       "  0.0006992086610116586,\n",
       "  0.0006856344794518571,\n",
       "  0.0006723280820270999,\n",
       "  0.0006592840972503303,\n",
       "  0.0006464972632506714,\n",
       "  0.0006339624254299044,\n",
       "  0.0006216745342640402,\n",
       "  0.0006096286431476552,\n",
       "  0.0005978199062253549,\n",
       "  0.0005862435763511903,\n",
       "  0.0005748950029634753,\n",
       "  0.0005637696302057991,\n",
       "  0.0005528629948564133,\n",
       "  0.000542170724468693,\n",
       "  0.0005316885354848112,\n",
       "  0.00052141223140439,\n",
       "  0.0005113377009516709,\n",
       "  0.0005014609163783236,\n",
       "  0.0004917779316726093,\n",
       "  0.0004822848809225327,\n",
       "  0.00047297797661502764,\n",
       "  0.00046385350807946144,\n",
       "  0.0004549078398374193,\n",
       "  0.0004461374101183589,\n",
       "  0.0004375387292780302,\n",
       "  0.0004291083783464128,\n",
       "  0.0004208430075889895,\n",
       "  0.0004127393350459418,\n",
       "  0.0004047941451509087,\n",
       "  0.00039700428736093703,\n",
       "  0.00038936667485455195,\n",
       "  0.00038187828313300423,\n",
       "  0.000374536148879529,\n",
       "  0.00036733736855499563,\n",
       "  0.00036027909725285884,\n",
       "  0.00035335854749918207,\n",
       "  0.00034657298803691564,\n",
       "  0.00033991974269841416,\n",
       "  0.00033339618926679,\n",
       "  0.00032699975836173665,\n",
       "  0.00032072793237339467,\n",
       "  0.00031457824439038183,\n",
       "  0.0003085482771620066,\n",
       "  0.0003026356620926628,\n",
       "  0.00029683807822962195,\n",
       "  0.0002911532513204524,\n",
       "  0.00028557895278336624,\n",
       "  0.00028011299885553133,\n",
       "  0.00027475324966170546,\n",
       "  0.0002694976082780702,\n",
       "  0.0002643440198734968,\n",
       "  0.00025929047088390583,\n",
       "  0.0002543349881060178,\n",
       "  0.00024947563793420674,\n",
       "  0.00024471052551810725,\n",
       "  0.0002400377939809157,\n",
       "  0.00023545562364101226,\n",
       "  0.00023096223127810626,\n",
       "  0.00022655586936835197,\n",
       "  0.00022223482533744726,\n",
       "  0.00021799742089289402,\n",
       "  0.0002138420113242326,\n",
       "  0.00020976698474255696,\n",
       "  0.0002057707615583423,\n",
       "  0.00020185179366313263,\n",
       "  0.0001980085639189319,\n",
       "  0.0001942395854384776,\n",
       "  0.00019054340103435955,\n",
       "  0.0001869185825975857,\n",
       "  0.00018336373046288866,\n",
       "  0.00017987747291925177,\n",
       "  0.00017645846555780658,\n",
       "  0.00017310539076317074,\n",
       "  0.00016981695718856947,\n",
       "  0.000166591899142447,\n",
       "  0.0001634289761890486,\n",
       "  0.00016032697251466718,\n",
       "  0.00015728469653226475,\n",
       "  0.00015430098031673562,\n",
       "  0.00015137467916240813,\n",
       "  0.00014850467111246376,\n",
       "  0.0001456898565023759,\n",
       "  0.00014292915747542989,\n",
       "  0.00014022151760842265,\n",
       "  0.00013756590138253545,\n",
       "  0.0001349612938680731,\n",
       "  0.00013240670023668093,\n",
       "  0.00012990114538758335,\n",
       "  0.00012744367353673092,\n",
       "  0.00012503334782790556,\n",
       "  0.0001226692499575145,\n",
       "  0.00012035047980231246,\n",
       "  0.0001180761550401502,\n",
       "  0.00011584541081881764,\n",
       "  0.00011365739938434119,\n",
       "  0.00011151128971326089,\n",
       "  0.00010940626725158247,\n",
       "  0.00010734153347941654,\n",
       "  0.00010531630569052177,\n",
       "  0.00010332981661972983,\n",
       "  0.00010138131411456141,\n",
       "  9.947006090247925e-05],\n",
       " [4.895443999328478,\n",
       "  4.793085843633167,\n",
       "  4.692883173604833,\n",
       "  4.594790999021021,\n",
       "  4.498764629993495,\n",
       "  4.404760129085936,\n",
       "  4.312734421369907,\n",
       "  4.22264532163462,\n",
       "  4.13445153490354,\n",
       "  4.048112646740728,\n",
       "  3.963589109227223,\n",
       "  3.8808422250145456,\n",
       "  3.7998341305468104,\n",
       "  3.7205277789864,\n",
       "  3.642886923121628,\n",
       "  3.566876098407797,\n",
       "  3.492460606226585,\n",
       "  3.4196064974120777,\n",
       "  3.3482805560707796,\n",
       "  3.278450283710519,\n",
       "  3.210083883685579,\n",
       "  3.1431502459606246,\n",
       "  3.077618932192972,\n",
       "  3.0134601611308027,\n",
       "  2.9506447943236416,\n",
       "  2.889144322140626,\n",
       "  2.8289308500914343,\n",
       "  2.7699770854446024,\n",
       "  2.7122563241375586,\n",
       "  2.6557424379726786,\n",
       "  2.600409862093635,\n",
       "  2.5462335827362863,\n",
       "  2.49318912524831,\n",
       "  2.441252542372028,\n",
       "  2.390400402784694,\n",
       "  2.3406097798907926,\n",
       "  2.291858240860905,\n",
       "  2.2441238359117923,\n",
       "  2.1973850878224237,\n",
       "  2.151620981680867,\n",
       "  2.106810954856964,\n",
       "  2.062934887195832,\n",
       "  2.0199730914274023,\n",
       "  1.9779063037872051,\n",
       "  1.9367156748438026,\n",
       "  1.8963827605283494,\n",
       "  1.8568895133617567,\n",
       "  1.8182182738751922,\n",
       "  1.7803517622196563,\n",
       "  1.7432730699604542,\n",
       "  1.706965652052496,\n",
       "  1.671413318992496,\n",
       "  1.6366002291440989,\n",
       "  1.6025108812322306,\n",
       "  1.569130107002864,\n",
       "  1.5364430640446447,\n",
       "  1.5044352287687313,\n",
       "  1.473092389543467,\n",
       "  1.44240063998043,\n",
       "  1.412346372368543,\n",
       "  1.3829162712530239,\n",
       "  1.3540973071559024,\n",
       "  1.3258767304352101,\n",
       "  1.2982420652795255,\n",
       "  1.2711811038351426,\n",
       "  1.244681900462792,\n",
       "  1.218732766121238,\n",
       "  1.193322262874788,\n",
       "  1.1684391985221554,\n",
       "  1.1440726213439507,\n",
       "  1.1202118149662175,\n",
       "  1.096846293337443,\n",
       "  1.0739657958166546,\n",
       "  1.0515602823700423,\n",
       "  1.0296199288738261,\n",
       "  1.0081351225210486,\n",
       "  0.9870964573299025,\n",
       "  0.9664947297515508,\n",
       "  0.9463209343751107,\n",
       "  0.9265662597277186,\n",
       "  0.9072220841676317,\n",
       "  0.8882799718682672,\n",
       "  0.8697316688912116,\n",
       "  0.8515690993462214,\n",
       "  0.8337843616363293,\n",
       "  0.8163697247861476,\n",
       "  0.7993176248515413,\n",
       "  0.7826206614088584,\n",
       "  0.7662715941219457,\n",
       "  0.7502633393852374,\n",
       "  0.7345889670411497,\n",
       "  0.7192416971702146,\n",
       "  0.7042148969521614,\n",
       "  0.6895020775964722,\n",
       "  0.6750968913407293,\n",
       "  0.6609931285152195,\n",
       "  0.6471847146722666,\n",
       "  0.6336657077787208,\n",
       "  0.6204302954702087,\n",
       "  0.6074727923655215,\n",
       "  0.5947876374398173,\n",
       "  0.5823693914551058,\n",
       "  0.5702127344465845,\n",
       "  0.5583124632634853,\n",
       "  0.5466634891629103,\n",
       "  0.53526083545534,\n",
       "  0.524099635200401,\n",
       "  0.5131751289514486,\n",
       "  0.5024826625476984,\n",
       "  0.49201768495237896,\n",
       "  0.4817757461356376,\n",
       "  0.47175249500072886,\n",
       "  0.46194367735217473,\n",
       "  0.45234513390438796,\n",
       "  0.4429527983294623,\n",
       "  0.433762695342631,\n",
       "  0.42477093882400396,\n",
       "  0.41597372997507615,\n",
       "  0.40736735550864844,\n",
       "  0.3989481858705372,\n",
       "  0.39071267349170996,\n",
       "  0.3826573510691963,\n",
       "  0.37477882987429145,\n",
       "  0.3670737980865167,\n",
       "  0.3595390191516054,\n",
       "  0.35217133016204566,\n",
       "  0.34496764025841203,\n",
       "  0.33792492904991017,\n",
       "  0.3310402450523171,\n",
       "  0.32431070414173124,\n",
       "  0.3177334880223232,\n",
       "  0.3113058427063186,\n",
       "  0.3050250770044946,\n",
       "  0.2988885610253793,\n",
       "  0.2928937246814343,\n",
       "  0.2870380562003925,\n",
       "  0.28131910064004473,\n",
       "  0.2757344584047505,\n",
       "  0.27028178376197537,\n",
       "  0.2649587833572144,\n",
       "  0.2597632147258036,\n",
       "  0.2546928848000282,\n",
       "  0.24974564841027916,\n",
       "  0.2449194067788701,\n",
       "  0.2402121060054997,\n",
       "  0.235621735543393,\n",
       "  0.23114632666532928,\n",
       "  0.22678395091912065,\n",
       "  0.22253271857214246,\n",
       "  0.2183907770449927,\n",
       "  0.21435630933458663,\n",
       "  0.2104275324272338,\n",
       "  0.20660269570283318,\n",
       "  0.20288007933147048,\n",
       "  0.19925799266425076,\n",
       "  0.1957347726206387,\n",
       "  0.19230878207499455,\n",
       "  0.18897840824550785,\n",
       "  0.18574206108917346,\n",
       "  0.1825981717069875,\n",
       "  0.17954519076399197,\n",
       "  0.1765815869292756,\n",
       "  0.17370584534158864,\n",
       "  0.1709164661064295,\n",
       "  0.16821196283110207,\n",
       "  0.16559086120442446,\n",
       "  0.1630516976280706,\n",
       "  0.16059301790672165,\n",
       "  0.15821337600433605,\n",
       "  0.1559113328739211,\n",
       "  0.15368545536796613,\n",
       "  0.15153431523666008,\n",
       "  0.14945648822060653,\n",
       "  0.14745055324439993,\n",
       "  0.14551509171688515,\n",
       "  0.14364868694318045,\n",
       "  0.1418499236528766,\n",
       "  0.14011738764792483,\n",
       "  0.13844966557266344,\n",
       "  0.1368453448075604,\n",
       "  0.13530301348693746,\n",
       "  0.13382126063986913,\n",
       "  0.13239867645230388,\n",
       "  0.13103385264709155,\n",
       "  0.12972538297755457,\n",
       "  0.12847186382907183,\n",
       "  0.1272718949219006,\n",
       "  0.12612408010768472,\n",
       "  0.12502702825093992,\n",
       "  0.12397935418625268,\n",
       "  0.12297967974099663,\n",
       "  0.12202663481309038,\n",
       "  0.1211188584927912,\n",
       "  0.1202550002173555,\n",
       "  0.11943372094733434,\n",
       "  0.1186536943533396,\n",
       "  0.11791360800240874,\n",
       "  0.11721216453336812,\n",
       "  0.11654808281121246,\n",
       "  0.1159200990510295,\n",
       "  0.11532696790279556,\n",
       "  0.11476746348907256,\n",
       "  0.114240380388532,\n",
       "  0.11374453455911583,\n",
       "  0.11327876419558004,\n",
       "  0.11284193051702518,\n",
       "  0.11243291848105216,\n",
       "  0.11205063742195895,\n",
       "  0.11169402161137208,\n",
       "  0.11136203074046347,\n",
       "  0.11105365032369148,\n",
       "  0.11076789202472692,\n",
       "  0.11050379390587971,\n",
       "  0.11026042060288364,\n",
       "  0.11003686342745386,\n",
       "  0.10983224040042139,\n",
       "  0.10964569621865858,\n",
       "  0.10947640215928146,\n",
       "  0.10932355592485252,\n",
       "  0.10918638143348752,\n",
       "  0.10906412855789156,\n",
       "  0.10895607281738634,\n",
       "  0.10886151502704267,\n",
       "  0.1087797809079881,\n",
       "  0.10871022066288102,\n",
       "  0.10865220852048973,\n",
       "  0.108605142253158,\n",
       "  0.10856844267081595,\n",
       "  0.10854155309500917,\n",
       "  0.10852393881628804,\n",
       "  0.10851508653805866,\n",
       "  0.10851450380986076,\n",
       "  0.10852171845278456,\n",
       "  0.1085362779796075,\n",
       "  0.10855774901196254,\n",
       "  0.10858571669671273,\n",
       "  0.1086197841235027,\n",
       "  0.10865957174525542,\n",
       "  0.1087047168032244,\n",
       "  0.10875487275805436,\n",
       "  0.10880970872809893,\n",
       "  0.1088689089361525,\n",
       "  0.10893217216555837,\n",
       "  0.10899921122655261,\n",
       "  0.10906975243356876,\n",
       "  0.1091435350941193,\n",
       "  0.10922031100973588,\n",
       "  0.1092998439894111,\n",
       "  0.10938190937583152,\n",
       "  0.10946629358465461,\n",
       "  0.1095527936569756,\n",
       "  0.10964121682509284,\n",
       "  0.10973138009161772,\n",
       "  0.10982310982187848,\n",
       "  0.10991624134959448,\n",
       "  0.11001061859567351,\n",
       "  0.11010609370002375,\n",
       "  0.11020252666618256,\n",
       "  0.1102997850185712,\n",
       "  0.11039774347213446,\n",
       "  0.11049628361413558,\n",
       "  0.11059529359782055,\n",
       "  0.11069466784770125,\n",
       "  0.11079430677614537,\n",
       "  0.11089411651098095,\n",
       "  0.11099400863382018,\n",
       "  0.1110938999287928,\n",
       "  0.11119371214136352,\n",
       "  0.1112933717469441,\n",
       "  0.11139280972896791,\n",
       "  0.11149196136612857,\n",
       "  0.11159076602848492,\n",
       "  0.11168916698209577,\n",
       "  0.11178711120192175,\n",
       "  0.11188454919267404,\n",
       "  0.11198143481734334,\n",
       "  0.1120777251330887,\n",
       "  0.11217338023426532,\n",
       "  0.11226836310226523,\n",
       "  0.11236263946193688,\n",
       "  0.11245617764433614,\n",
       "  0.11254894845552703,\n",
       "  0.11264092505123457,\n",
       "  0.11273208281706917,\n",
       "  0.11282239925413434,\n",
       "  0.11291185386978082,\n",
       "  0.11300042807328832,\n",
       "  0.11308810507629966,\n",
       "  0.11317486979776964,\n",
       "  0.11326070877327667,\n",
       "  0.1133456100684911,\n",
       "  0.11342956319660837,\n",
       "  0.11351255903963768,\n",
       "  0.11359458977331513,\n",
       "  0.11367564879551198,\n",
       "  0.11375573065799827,\n",
       "  0.11383483100139584,\n",
       "  0.11391294649319875,\n",
       "  0.11399007476870364,\n",
       "  0.11406621437476157,\n",
       "  0.11414136471617674,\n",
       "  0.1142155260046786,\n",
       "  0.1142886992103329,\n",
       "  0.11436088601528734,\n",
       "  0.11443208876973486,\n",
       "  0.11450231045002407,\n",
       "  0.11457155461880184,\n",
       "  0.11463982538708106,\n",
       "  0.11470712737820055,\n",
       "  0.11477346569351386,\n",
       "  0.11483884587980761,\n",
       "  0.11490327389830829,\n",
       "  0.114966756095251,\n",
       "  0.11502929917391748,\n",
       "  0.11509091016805602,\n",
       "  0.11515159641668296,\n",
       "  0.11521136554012389,\n",
       "  0.11527022541730034,\n",
       "  0.1153281841641828,\n",
       "  0.11538525011332793,\n",
       "  0.11544143179451448,\n",
       "  0.11549673791635552,\n",
       "  0.11555117734890331,\n",
       "  0.11560475910714889,\n",
       "  0.11565749233541413,\n",
       "  0.1157093862925784,\n",
       "  0.11576045033810027,\n",
       "  0.11581069391879434,\n",
       "  0.11586012655634316,\n",
       "  0.11590875783548067,\n",
       "  0.11595659739285671,\n",
       "  0.116003654906513,\n",
       "  0.1160499400859644,\n",
       "  0.1160954626628392,\n",
       "  0.11614023238206655,\n",
       "  0.11618425899358609,\n",
       "  0.11622755224453483,\n",
       "  0.11627012187191463,\n",
       "  0.11631197759569997,\n",
       "  0.11635312911237819,\n",
       "  0.11639358608886682,\n",
       "  0.11643335815684974,\n",
       "  0.11647245490744941,\n",
       "  0.11651088588626769,\n",
       "  0.11654866058874841,\n",
       "  0.11658578845584329,\n",
       "  0.11662227887000187])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 600)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2(ind):\n",
    "    # Step 1 generate G and sigma\n",
    "    # d=3 p1=p2=p3=10 r=(1,2,2,2,2,2,1)\n",
    "    # norm(A)=norm(sigma)=5\n",
    "    # T = [1000,1200,1400,1600,2000]\n",
    "    p_vec=[4,4,4]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[4,4]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    N=600\n",
    "    scipy.random.seed()\n",
    "    mtl_rank = [1,1,1,1,1,1]\n",
    "    global G1; global G2; global G3; global sigma; global G4; global G5; global G6;\n",
    "    global A_ts; global A_mat\n",
    "    G1 = np.linalg.svd(np.random.normal(0,1,p_vec1[0]*p_vec1[0]).reshape(p_vec1[0],p_vec1[0]))[0][:,0:mtl_rank[1]].reshape(mtl_rank[0],p_vec1[0],mtl_rank[1],order=\"F\")\n",
    "    G2 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[1]*mtl_rank[1])).reshape(p_vec1[1]*mtl_rank[1],p_vec1[1]*mtl_rank[1]))[0][:,0:mtl_rank[2]].reshape(mtl_rank[1],p_vec1[1],mtl_rank[2],order=\"F\")\n",
    "    #G3 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[2]*mtl_rank[2])).reshape(p_vec1[2]*mtl_rank[2],p_vec1[2]*mtl_rank[2]))[0][:,0:mtl_rank[3]].reshape(mtl_rank[2],p_vec1[2],mtl_rank[3],order=\"F\")\n",
    "    sigma = np.diag(np.random.normal(0,1,mtl_rank[2]))\n",
    "    sigma = 5*sigma/np.linalg.norm(sigma)\n",
    "    G4 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[0]*mtl_rank[3])).reshape(p_vec[0]*mtl_rank[3],p_vec[0]*mtl_rank[3]))[2][0:mtl_rank[2],:].reshape(mtl_rank[2],p_vec[0],mtl_rank[3],order=\"F\")\n",
    "    G5 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[1]*mtl_rank[4])).reshape(p_vec[1]*mtl_rank[4],p_vec[1]*mtl_rank[4]))[2][0:mtl_rank[3],:].reshape(mtl_rank[3],p_vec[1],mtl_rank[4],order=\"F\")\n",
    "    G6 = np.linalg.svd(np.random.normal(0,1,p_vec[2]*p_vec[2]).reshape(p_vec[2],p_vec[2]))[2][0:mtl_rank[4],:].reshape(mtl_rank[4],p_vec[2],mtl_rank[5],order=\"F\")\n",
    "    A_ts = core_to_tensor1([G1,G2,sigma,G4,G5,G6], p_vec1+p_vec)\n",
    "    #A_ts = TTOI(A_ts, [2,2,2,2,2], iter=4, tol=1e-3)[-1]\n",
    "    #A_mat = A_ts.reshape(p, p, order=\"F\")###\n",
    "    A_mat = A_ts.reshape(p1, p, order=\"F\")\n",
    "    #A_mat = A_mat.reshape(p,p)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "\n",
    "        \n",
    "    result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,1,1,1], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d3(ind):\n",
    "    # Step 1 generate G and sigma\n",
    "    # d=3 p1=p2=p3=10 r=(1,2,2,2,2,2,1)\n",
    "    # norm(A)=norm(sigma)=5\n",
    "    # T = [1000,1200,1400,1600,2000]\n",
    "    p_vec=[5,5,5]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[5,5]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    N=600\n",
    "    scipy.random.seed()\n",
    "    mtl_rank = [1,1,1,1,1,1]\n",
    "    global G1; global G2; global G3; global sigma; global G4; global G5; global G6;\n",
    "    global A_ts; global A_mat\n",
    "    G1 = np.linalg.svd(np.random.normal(0,1,p_vec1[0]*p_vec1[0]).reshape(p_vec1[0],p_vec1[0]))[0][:,0:mtl_rank[1]].reshape(mtl_rank[0],p_vec1[0],mtl_rank[1],order=\"F\")\n",
    "    G2 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[1]*mtl_rank[1])).reshape(p_vec1[1]*mtl_rank[1],p_vec1[1]*mtl_rank[1]))[0][:,0:mtl_rank[2]].reshape(mtl_rank[1],p_vec1[1],mtl_rank[2],order=\"F\")\n",
    "    #G3 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[2]*mtl_rank[2])).reshape(p_vec1[2]*mtl_rank[2],p_vec1[2]*mtl_rank[2]))[0][:,0:mtl_rank[3]].reshape(mtl_rank[2],p_vec1[2],mtl_rank[3],order=\"F\")\n",
    "    sigma = np.diag(np.random.normal(0,1,mtl_rank[2]))\n",
    "    sigma = 5*sigma/np.linalg.norm(sigma)\n",
    "    G4 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[0]*mtl_rank[3])).reshape(p_vec[0]*mtl_rank[3],p_vec[0]*mtl_rank[3]))[2][0:mtl_rank[2],:].reshape(mtl_rank[2],p_vec[0],mtl_rank[3],order=\"F\")\n",
    "    G5 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[1]*mtl_rank[4])).reshape(p_vec[1]*mtl_rank[4],p_vec[1]*mtl_rank[4]))[2][0:mtl_rank[3],:].reshape(mtl_rank[3],p_vec[1],mtl_rank[4],order=\"F\")\n",
    "    G6 = np.linalg.svd(np.random.normal(0,1,p_vec[2]*p_vec[2]).reshape(p_vec[2],p_vec[2]))[2][0:mtl_rank[4],:].reshape(mtl_rank[4],p_vec[2],mtl_rank[5],order=\"F\")\n",
    "    A_ts = core_to_tensor1([G1,G2,sigma,G4,G5,G6], p_vec1+p_vec)\n",
    "    #A_ts = TTOI(A_ts, [2,2,2,2,2], iter=4, tol=1e-3)[-1]\n",
    "    #A_mat = A_ts.reshape(p, p, order=\"F\")###\n",
    "    A_mat = A_ts.reshape(p1, p, order=\"F\")\n",
    "    #A_mat = A_mat.reshape(p,p)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "\n",
    "        \n",
    "    result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,1,1,1], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d4(ind):\n",
    "    # Step 1 generate G and sigma\n",
    "    # d=3 p1=p2=p3=10 r=(1,2,2,2,2,2,1)\n",
    "    # norm(A)=norm(sigma)=5\n",
    "    # T = [1000,1200,1400,1600,2000]\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    N=600\n",
    "    scipy.random.seed()\n",
    "    mtl_rank = [1,1,1,1,1,1]\n",
    "    global G1; global G2; global G3; global sigma; global G4; global G5; global G6;\n",
    "    global A_ts; global A_mat\n",
    "    G1 = np.linalg.svd(np.random.normal(0,1,p_vec1[0]*p_vec1[0]).reshape(p_vec1[0],p_vec1[0]))[0][:,0:mtl_rank[1]].reshape(mtl_rank[0],p_vec1[0],mtl_rank[1],order=\"F\")\n",
    "    G2 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[1]*mtl_rank[1])).reshape(p_vec1[1]*mtl_rank[1],p_vec1[1]*mtl_rank[1]))[0][:,0:mtl_rank[2]].reshape(mtl_rank[1],p_vec1[1],mtl_rank[2],order=\"F\")\n",
    "    #G3 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[2]*mtl_rank[2])).reshape(p_vec1[2]*mtl_rank[2],p_vec1[2]*mtl_rank[2]))[0][:,0:mtl_rank[3]].reshape(mtl_rank[2],p_vec1[2],mtl_rank[3],order=\"F\")\n",
    "    sigma = np.diag(np.random.normal(0,1,mtl_rank[2]))\n",
    "    sigma = 5*sigma/np.linalg.norm(sigma)\n",
    "    G4 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[0]*mtl_rank[3])).reshape(p_vec[0]*mtl_rank[3],p_vec[0]*mtl_rank[3]))[2][0:mtl_rank[2],:].reshape(mtl_rank[2],p_vec[0],mtl_rank[3],order=\"F\")\n",
    "    G5 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[1]*mtl_rank[4])).reshape(p_vec[1]*mtl_rank[4],p_vec[1]*mtl_rank[4]))[2][0:mtl_rank[3],:].reshape(mtl_rank[3],p_vec[1],mtl_rank[4],order=\"F\")\n",
    "    G6 = np.linalg.svd(np.random.normal(0,1,p_vec[2]*p_vec[2]).reshape(p_vec[2],p_vec[2]))[2][0:mtl_rank[4],:].reshape(mtl_rank[4],p_vec[2],mtl_rank[5],order=\"F\")\n",
    "    A_ts = core_to_tensor1([G1,G2,sigma,G4,G5,G6], p_vec1+p_vec)\n",
    "    #A_ts = TTOI(A_ts, [2,2,2,2,2], iter=4, tol=1e-3)[-1]\n",
    "    #A_mat = A_ts.reshape(p, p, order=\"F\")###\n",
    "    A_mat = A_ts.reshape(p1, p, order=\"F\")\n",
    "    #A_mat = A_mat.reshape(p,p)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "\n",
    "        \n",
    "    result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,1,1,1], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d5(ind):\n",
    "    # Step 1 generate G and sigma\n",
    "    # d=3 p1=p2=p3=10 r=(1,2,2,2,2,2,1)\n",
    "    # norm(A)=norm(sigma)=5\n",
    "    # T = [1000,1200,1400,1600,2000]\n",
    "    p_vec=[8,8,8]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[8,8]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    N=600\n",
    "    scipy.random.seed()\n",
    "    mtl_rank = [1,1,1,1,1,1]\n",
    "    global G1; global G2; global G3; global sigma; global G4; global G5; global G6;\n",
    "    global A_ts; global A_mat\n",
    "    G1 = np.linalg.svd(np.random.normal(0,1,p_vec1[0]*p_vec1[0]).reshape(p_vec1[0],p_vec1[0]))[0][:,0:mtl_rank[1]].reshape(mtl_rank[0],p_vec1[0],mtl_rank[1],order=\"F\")\n",
    "    G2 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[1]*mtl_rank[1])).reshape(p_vec1[1]*mtl_rank[1],p_vec1[1]*mtl_rank[1]))[0][:,0:mtl_rank[2]].reshape(mtl_rank[1],p_vec1[1],mtl_rank[2],order=\"F\")\n",
    "    #G3 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[2]*mtl_rank[2])).reshape(p_vec1[2]*mtl_rank[2],p_vec1[2]*mtl_rank[2]))[0][:,0:mtl_rank[3]].reshape(mtl_rank[2],p_vec1[2],mtl_rank[3],order=\"F\")\n",
    "    sigma = np.diag(np.random.normal(0,1,mtl_rank[2]))\n",
    "    sigma = 5*sigma/np.linalg.norm(sigma)\n",
    "    G4 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[0]*mtl_rank[3])).reshape(p_vec[0]*mtl_rank[3],p_vec[0]*mtl_rank[3]))[2][0:mtl_rank[2],:].reshape(mtl_rank[2],p_vec[0],mtl_rank[3],order=\"F\")\n",
    "    G5 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[1]*mtl_rank[4])).reshape(p_vec[1]*mtl_rank[4],p_vec[1]*mtl_rank[4]))[2][0:mtl_rank[3],:].reshape(mtl_rank[3],p_vec[1],mtl_rank[4],order=\"F\")\n",
    "    G6 = np.linalg.svd(np.random.normal(0,1,p_vec[2]*p_vec[2]).reshape(p_vec[2],p_vec[2]))[2][0:mtl_rank[4],:].reshape(mtl_rank[4],p_vec[2],mtl_rank[5],order=\"F\")\n",
    "    A_ts = core_to_tensor1([G1,G2,sigma,G4,G5,G6], p_vec1+p_vec)\n",
    "    #A_ts = TTOI(A_ts, [2,2,2,2,2], iter=4, tol=1e-3)[-1]\n",
    "    #A_mat = A_ts.reshape(p, p, order=\"F\")###\n",
    "    A_mat = A_ts.reshape(p1, p, order=\"F\")\n",
    "    #A_mat = A_mat.reshape(p,p)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "\n",
    "        \n",
    "    result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,1,1,1], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d6(ind):\n",
    "    # Step 1 generate G and sigma\n",
    "    # d=3 p1=p2=p3=10 r=(1,2,2,2,2,2,1)\n",
    "    # norm(A)=norm(sigma)=5\n",
    "    # T = [1000,1200,1400,1600,2000]\n",
    "    p_vec=[10,10,10]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[10,10]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    N=600\n",
    "    scipy.random.seed()\n",
    "    mtl_rank = [1,1,1,1,1,1]\n",
    "    global G1; global G2; global G3; global sigma; global G4; global G5; global G6;\n",
    "    global A_ts; global A_mat\n",
    "    G1 = np.linalg.svd(np.random.normal(0,1,p_vec1[0]*p_vec1[0]).reshape(p_vec1[0],p_vec1[0]))[0][:,0:mtl_rank[1]].reshape(mtl_rank[0],p_vec1[0],mtl_rank[1],order=\"F\")\n",
    "    G2 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[1]*mtl_rank[1])).reshape(p_vec1[1]*mtl_rank[1],p_vec1[1]*mtl_rank[1]))[0][:,0:mtl_rank[2]].reshape(mtl_rank[1],p_vec1[1],mtl_rank[2],order=\"F\")\n",
    "    #G3 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[2]*mtl_rank[2])).reshape(p_vec1[2]*mtl_rank[2],p_vec1[2]*mtl_rank[2]))[0][:,0:mtl_rank[3]].reshape(mtl_rank[2],p_vec1[2],mtl_rank[3],order=\"F\")\n",
    "    sigma = np.diag(np.random.normal(0,1,mtl_rank[2]))\n",
    "    sigma = 5*sigma/np.linalg.norm(sigma)\n",
    "    G4 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[0]*mtl_rank[3])).reshape(p_vec[0]*mtl_rank[3],p_vec[0]*mtl_rank[3]))[2][0:mtl_rank[2],:].reshape(mtl_rank[2],p_vec[0],mtl_rank[3],order=\"F\")\n",
    "    G5 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[1]*mtl_rank[4])).reshape(p_vec[1]*mtl_rank[4],p_vec[1]*mtl_rank[4]))[2][0:mtl_rank[3],:].reshape(mtl_rank[3],p_vec[1],mtl_rank[4],order=\"F\")\n",
    "    G6 = np.linalg.svd(np.random.normal(0,1,p_vec[2]*p_vec[2]).reshape(p_vec[2],p_vec[2]))[2][0:mtl_rank[4],:].reshape(mtl_rank[4],p_vec[2],mtl_rank[5],order=\"F\")\n",
    "    A_ts = core_to_tensor1([G1,G2,sigma,G4,G5,G6], p_vec1+p_vec)\n",
    "    #A_ts = TTOI(A_ts, [2,2,2,2,2], iter=4, tol=1e-3)[-1]\n",
    "    #A_mat = A_ts.reshape(p, p, order=\"F\")###\n",
    "    A_mat = A_ts.reshape(p1, p, order=\"F\")\n",
    "    #A_mat = A_mat.reshape(p,p)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "\n",
    "        \n",
    "    result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,1,1,1], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.61068820953369\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(25) as p:\n",
    "        result = p.map(d4,l)\n",
    "        with open('try.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.731523036956787\n",
      "5.557847499847412\n",
      "8.754189014434814\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4a02252165f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'N600S5.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(30) as p:\n",
    "        result = p.map(d1,l)\n",
    "        with open('p'+str(33)+'N600S5.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(30) as p:\n",
    "        result = p.map(d2,l)\n",
    "        with open('p'+str(44)+'N600S5.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(30) as p:\n",
    "        result = p.map(d3,l)\n",
    "        with open('p'+str(55)+'N600S5.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(30) as p:\n",
    "        result = p.map(d4,l)\n",
    "        with open('p'+str(66)+'N600S5.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(30) as p:\n",
    "        result = p.map(d5,l)\n",
    "        with open('p'+str(88)+'N600S5.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(30) as p:\n",
    "        result = p.map(d6,l)\n",
    "        with open('p'+str(1010)+'N600S5.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('try.pkl','rb') as f:\n",
    "    result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2057386755685179\n",
      "0.027961250830623428\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "list1 = []\n",
    "list2 = []\n",
    "for i in range(len(result)):\n",
    "    #print(result[i][0][-1])\n",
    "    if result[i][0][-1]<0.01 and len(result[i][1])<2000:\n",
    "        list1.append(result[i][1][-1])\n",
    "        #print(len(result[i][1]))\n",
    "        list2.append(len(result[i][1]))\n",
    "print(np.mean(list1))\n",
    "print(np.std(list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d1(ind):\n",
    "    result = 100**3\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    l = list(range(900000000))\n",
    "    with Pool(30) as p:\n",
    "        result = p.map(d1,l)\n",
    "        with open('p'+str(1010)+'tt.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "def d1(ind):\n",
    "    return 100**2\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(399999))\n",
    "    with Pool(30) as p:\n",
    "        result = p.map(d1,l)\n",
    "        #with open('p'+str(1010)+'N600S5.pkl','wb') as f:\n",
    "            #pickle.dump(result, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
