{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=1\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=1\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=1\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=1\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "from tensorly import tt_to_tensor\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch\n",
    "from multiprocessing import Pool\n",
    "import scipy\n",
    "from tensorly.tenalg import contract\n",
    "import pickle\n",
    "import itertools\n",
    "import scipy\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensordot(A,B,modes):\n",
    "    return contract(A,modes[0],B,modes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TTOI(Y_tensor, r_vec, iter, tol):\n",
    "    dim_vec = Y_tensor.shape\n",
    "    d = len(dim_vec)\n",
    "    X_hat_arr = [None] * iter\n",
    "    V_prod_arr = [None] * int(np.floor(iter/2)+1)\n",
    "    U_prod_arr = [None] * int(np.ceil(iter/2))\n",
    "    Y_arr = [None] * (d-1)\n",
    "    for i in range(d-1):\n",
    "        Y_arr[i] = Y_tensor.reshape(np.prod(dim_vec[:i+1]), np.prod(dim_vec[i+1:]), order=\"F\")\n",
    "    V_prod_arr[0] = [1] * (d-1)\n",
    "    n = 0\n",
    "    chg = np.Inf\n",
    "    while n<iter and chg > tol:\n",
    "        if n==0:\n",
    "            U_prod_arr[int(n / 2)] = [None] * (d - 1)\n",
    "            Y_tilde_arr = [None] * (d - 2)\n",
    "            U_temp, _, _ = np.linalg.svd(Y_arr[0])\n",
    "            U_temp = U_temp[:, :r_vec[0]]\n",
    "            U_prod_arr[int(n / 2)][0] = U_temp\n",
    "            for k in range(1, d - 1):\n",
    "                Y_temp = np.kron(np.eye(dim_vec[k]), U_prod_arr[int(n / 2)][k - 1]).T @ Y_arr[k]\n",
    "                Y_tilde_arr[k - 1] = Y_temp.reshape(r_vec[k - 1], np.prod(dim_vec[k:]), order=\"F\")\n",
    "                U_temp, _, _ = np.linalg.svd(Y_temp)\n",
    "                U_temp = U_temp[:, :r_vec[k]]\n",
    "                U_prod_arr[int(n / 2)][k] = np.kron(np.eye(dim_vec[k]), U_prod_arr[int(n / 2)][k - 1]) @ U_temp\n",
    "            X_hat_temp = U_prod_arr[int(n / 2)][d - 2].T @ Y_arr[d - 2]\n",
    "            X_hat_arr[n] = (U_prod_arr[int(n / 2)][d - 2] @ X_hat_temp).reshape(dim_vec, order=\"F\")\n",
    "        elif n % 2 == 0:\n",
    "            U_prod_arr[int(n/2)] = [None] * (d-1)\n",
    "            Y_tilde_arr = [None] * (d-2)\n",
    "            U_temp, _, _ = np.linalg.svd(Y_arr[0]@V_prod_arr[int(n/2)][d-2])\n",
    "            U_temp = U_temp[:,:r_vec[0]]\n",
    "            U_prod_arr[int(n/2)][0] = U_temp\n",
    "            for k in range(1,d-1):\n",
    "                Y_temp = np.kron(np.eye(dim_vec[k]),U_prod_arr[int(n/2)][k-1]).T@Y_arr[k]\n",
    "                Y_tilde_arr[k-1] = Y_temp.reshape(r_vec[k-1],np.prod(dim_vec[k:]),order=\"F\")\n",
    "                U_temp, _, _ = np.linalg.svd(Y_temp@V_prod_arr[int(n/2)][d-k-2])\n",
    "                U_temp = U_temp[:,:r_vec[k]]\n",
    "                U_prod_arr[int(n/2)][k] = np.kron(np.eye(dim_vec[k]),U_prod_arr[int(n/2)][k-1])@U_temp\n",
    "            X_hat_temp = U_prod_arr[int(n/2)][d-2].T@Y_arr[d-2]\n",
    "            X_hat_arr[n] = (U_prod_arr[int(n/2)][d-2]@X_hat_temp).reshape(dim_vec,order=\"F\")\n",
    "        else:\n",
    "            V_prod_arr[int((n+1)/2)] = [None] * (d-1)\n",
    "            _, _, V_temp = np.linalg.svd(U_prod_arr[int((n-1)/2)][d-2].T@Y_arr[d-2])\n",
    "            V_temp = V_temp[:r_vec[d-2],:].T\n",
    "            V_prod_arr[int((n+1)/2)][0] = V_temp\n",
    "            for k in range(1,d-1):\n",
    "                _, _, V_temp = np.linalg.svd(Y_tilde_arr[d-k-2]@np.kron(V_prod_arr[int((n+1)/2)][k-1],np.eye(dim_vec[d-k-1])))\n",
    "                V_temp = V_temp[:r_vec[d - k-2], :].T\n",
    "                V_prod_arr[int((n+1)/2)][k] = np.kron(V_prod_arr[int((n+1)/2)][k-1],np.eye(dim_vec[d-k-1]))@V_temp\n",
    "            X_hat_temp = Y_arr[0]@V_prod_arr[int((n+1)/2)][d-2]\n",
    "            X_hat_arr[n] = (X_hat_temp@V_prod_arr[int((n+1)/2)][d-2].T).reshape(dim_vec,order=\"F\")\n",
    "        n=n+1\n",
    "        if n>1:\n",
    "            chg = np.square(np.linalg.norm(X_hat_arr[n-1].reshape(np.prod(dim_vec),1),\"fro\"))-np.square(np.linalg.norm(X_hat_arr[n-2].reshape(np.prod(dim_vec),1),\"fro\"))\n",
    "\n",
    "    return [x for x in X_hat_arr if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGrad5(X, ranks, A):\n",
    "    p1, p2, p3, p4, p5 = X.shape\n",
    "    _, r1, r2, r3, r4, _ = ranks\n",
    "    factors = matrix_product_state(X, rank=ranks)\n",
    "    G1, G2, G3, G4, G5 = factors\n",
    "    G1 = G1.reshape(p1,r1,order=\"F\")\n",
    "    G5 = G5.reshape(r4,p5,order=\"F\")\n",
    "\n",
    "    G_ge2 = (tensordot(tensordot(tensordot(G2,G3,[2,0]),G4,[3,0]),G5,[4,0])).reshape(r1, p2*p3*p4*p5, order=\"F\")\n",
    "    A1 = (np.identity(p1)-G1@G1.T)@A.reshape(p1,p2*p3*p4*p5,order=\"F\")@G_ge2.T@np.linalg.inv(G_ge2@G_ge2.T)\n",
    "    delta_A1 = tensordot(tensordot(tensordot(tensordot(A1,G2,[1,0]),G3,[2,0]),G4,[3,0]),G5,[4,0])\n",
    "\n",
    "    G_ge3 = (tensordot(tensordot(G3,G4,[2,0]),G5,[3,0])).reshape(r2, p3*p4*p5, order=\"F\")\n",
    "    L_G2 = G2.reshape(p2*r1, r2, order=\"F\")\n",
    "    A2 = (np.identity(p2*r1)-L_G2@L_G2.T)@(np.kron(np.identity(p2), G1)).T@A.reshape(p1*p2,p3*p4*p5,order=\"F\")@G_ge3.T@np.linalg.inv(G_ge3@G_ge3.T)\n",
    "    delta_A2 = tensordot(tensordot(tensordot(tensordot(G1, A2.reshape([r1,p2,r2],order=\"F\"), [1, 0]), G3, [2, 0]), G4, [3, 0]), G5, [4,0])\n",
    "\n",
    "    G_ge4 = (tensordot(G4,G5,[2,0])).reshape(r3, p4*p5, order=\"F\")\n",
    "    L_G3 = G3.reshape(p3*r2, r3, order=\"F\")\n",
    "    G_le2 = (tensordot(G1,G2,[1,0])).reshape(p1*p2,r2, order=\"F\")\n",
    "    A3 = (np.identity(p3*r2)-L_G3@L_G3.T)@(np.kron(np.identity(p3), G_le2)).T@A.reshape(p1*p2*p3,p4*p5,order=\"F\")@G_ge4.T@np.linalg.inv(G_ge4@G_ge4.T)\n",
    "    delta_A3 = tensordot(tensordot(tensordot(tensordot(G1, G2, [1, 0]), A3.reshape([r2,p3,r3],order=\"F\"), [2, 0]), G4, [3, 0]), G5, [4,0])\n",
    "\n",
    "    L_G4 = G4.reshape(p4*r3, r4, order=\"F\")\n",
    "    G_le3 = (tensordot(tensordot(G1,G2,[1,0]),G3,[2,0])).reshape(p1*p2*p3,r3, order=\"F\")\n",
    "    A4 = (np.identity(p4*r3)-L_G4@L_G4.T)@(np.kron(np.identity(p4),G_le3)).T@A.reshape(p1*p2*p3*p4,p5,order=\"F\")@G5.T @np.linalg.inv(G5@G5.T)\n",
    "    delta_A4 = tensordot(tensordot(tensordot(tensordot(G1, G2, [1, 0]), G3, [2, 0]), A4.reshape([r3,p4,r4], order=\"F\"), [3, 0]),G5,[4,0])\n",
    "\n",
    "    G_le4 = (tensordot(tensordot(tensordot(G1,G2,[1,0]),G3,[2,0]),G4,[3,0])).reshape(p1*p2*p3*p4,r4,order=\"F\")\n",
    "    A5 = (np.kron(np.identity(p5), G_le4)).T@A.reshape(p1*p2*p3*p4*p5,1,order=\"F\")\n",
    "    delta_A5 = tensordot(tensordot(tensordot(tensordot(G1, G2, [1, 0]), G3, [2, 0]), G4,[3,0]),A5.reshape(r4,p5,order=\"F\"), [4, 0])\n",
    "\n",
    "    return delta_A1+delta_A2+delta_A3+delta_A4+delta_A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def PGD(Y, X, trueA, p_vec1, p_vec, mtl_rank, max_iter, tol):\n",
    "    p1, N = Y.shape\n",
    "    p, _ = X.shape\n",
    "    A_inittmp = (Y@X.T)/N\n",
    "    A_initts = TTOI(A_inittmp.reshape(p_vec1+p_vec,order=\"F\"),mtl_rank[1:-1],2,1e-4)[-1]\n",
    "    Amat = A_initts.reshape(p1,p,order=\"F\")\n",
    "    chg_list = [None] * max_iter\n",
    "    est_list = [None] * max_iter\n",
    "    n = 0\n",
    "    chg = np.inf\n",
    "    while n < max_iter and chg > tol:\n",
    "        start = time.time()\n",
    "        P = RGrad5(Amat.reshape(p_vec1+p_vec,order=\"F\"),mtl_rank,((Amat@X-Y)@X.T)/N)\n",
    "        Pmat = P.reshape(p1,p,order=\"F\")\n",
    "        eta = N*np.square(np.linalg.norm(Pmat,\"fro\"))/np.square(np.linalg.norm(Pmat@X,\"fro\"))\n",
    "        A_tmpmat = Amat - eta*Pmat\n",
    "        factors = matrix_product_state(A_tmpmat.reshape(p_vec1+p_vec,order=\"F\"), rank=mtl_rank)\n",
    "        A_newts = tt_to_tensor(factors)\n",
    "        A_newmat = A_newts.reshape(p1,p,order=\"F\")\n",
    "        chg_list[n] = np.linalg.norm(A_newmat-Amat, \"fro\")\n",
    "        est_list[n] = np.linalg.norm(A_newmat-trueA, \"fro\")\n",
    "        chg = np.linalg.norm(A_newmat-Amat, \"fro\")\n",
    "        if chg>10:\n",
    "            break\n",
    "        n=n+1\n",
    "        Amat = A_newmat\n",
    "        \n",
    "\n",
    "    return ([x for x in chg_list if x is not None],[x for x in est_list if x is not None],Amat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('33jointr2.pkl','rb') as f:\n",
    "    A_mat, A_ts= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7469435305966434"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda1=np.linalg.svd(A_ts.reshape(6,36*36,order=\"F\"))[1][:2]\n",
    "lambda2=np.linalg.svd(A_ts.reshape(36,6*36,order=\"F\"))[1][:2]\n",
    "lambda3=np.linalg.svd(A_ts.reshape(216,36,order=\"F\"))[1][:2]\n",
    "lambda4=np.linalg.svd(A_ts.reshape(216*6,6,order=\"F\"))[1][:2]\n",
    "lambdatotal=np.concatenate((lambda1,lambda2,lambda3,lambda4))\n",
    "np.min(lambdatotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d1(ind):\n",
    "    torch.random.seed()\n",
    "    N=200\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    a = list(range(1,4))\n",
    "    b = list(range(1,4))\n",
    "    c = list(range(1,4))\n",
    "    d = list(range(1,4))\n",
    "    global paramlist;\n",
    "    paramlist = list(itertools.product(a,b,c,d))\n",
    "    \n",
    "    result1 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in paramlist:\n",
    "        result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i[0]]+[i[1]]+[i[2]]+[i[3]]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result)\n",
    "        if result[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "    rBIC = []\n",
    "    rsigma = []\n",
    "    for i in range(len(result1)):\n",
    "        sigma = (np.linalg.norm(Y-result1[i][2]@X)**2)/(Y.shape[1])\n",
    "        a,b,c,d = paramlist[i]\n",
    "        df = 6*(a+d)+6*(a*b+b*c+c*d)+b\n",
    "        BIC = np.log(sigma)+0.02*np.log(Y.shape[1])*(df+1)/(Y.shape[1])\n",
    "        rBIC.append(BIC)\n",
    "        rsigma.append(np.log(sigma))\n",
    "\n",
    "    return (rBIC,paramlist[np.argsort(np.array(rBIC))[0]],t1,t2,rsigma,Y,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [37:34<00:00,  4.51s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2256.239568710327\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d1,l),total=500))\n",
    "        with open('N200.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2(ind):\n",
    "    torch.random.seed()\n",
    "    N=165\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    a = list(range(1,4))\n",
    "    b = list(range(1,4))\n",
    "    c = list(range(1,4))\n",
    "    d = list(range(1,4))\n",
    "    global paramlist;\n",
    "    paramlist = list(itertools.product(a,b,c,d))\n",
    "    \n",
    "    result1 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in paramlist:\n",
    "        result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i[0]]+[i[1]]+[i[2]]+[i[3]]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result)\n",
    "        if result[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "    rBIC = []\n",
    "    rsigma = []\n",
    "    for i in range(len(result1)):\n",
    "        sigma = (np.linalg.norm(Y-result1[i][2]@X)**2)/(Y.shape[1])\n",
    "        a,b,c,d = paramlist[i]\n",
    "        df = 6*(a+d)+6*(a*b+b*c+c*d)+b\n",
    "        BIC = np.log(sigma)+0.02*np.log(Y.shape[1])*(df+1)/(Y.shape[1])\n",
    "        rBIC.append(BIC)\n",
    "        rsigma.append(np.log(sigma))\n",
    "\n",
    "    return (rBIC,paramlist[np.argsort(np.array(rBIC))[0]],t1,t2,rsigma,Y,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [45:19<00:00,  5.44s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2723.2666358947754\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d2,l),total=500))\n",
    "        with open('N165.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d3(ind):\n",
    "    torch.random.seed()\n",
    "    N=130\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    a = list(range(1,4))\n",
    "    b = list(range(1,4))\n",
    "    c = list(range(1,4))\n",
    "    d = list(range(1,4))\n",
    "    global paramlist;\n",
    "    paramlist = list(itertools.product(a,b,c,d))\n",
    "    \n",
    "    result1 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in paramlist:\n",
    "        result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i[0]]+[i[1]]+[i[2]]+[i[3]]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result)\n",
    "        if result[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "    rBIC = []\n",
    "    rsigma = []\n",
    "    for i in range(len(result1)):\n",
    "        sigma = (np.linalg.norm(Y-result1[i][2]@X)**2)/(Y.shape[1])\n",
    "        a,b,c,d = paramlist[i]\n",
    "        df = 6*(a+d)+6*(a*b+b*c+c*d)+b\n",
    "        BIC = np.log(sigma)+0.02*np.log(Y.shape[1])*(df+1)/(Y.shape[1])\n",
    "        rBIC.append(BIC)\n",
    "        rsigma.append(np.log(sigma))\n",
    "\n",
    "    return (rBIC,paramlist[np.argsort(np.array(rBIC))[0]],t1,t2,rsigma,Y,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [53:29<00:00,  6.42s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3212.967806339264\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d3,l),total=500))\n",
    "        with open('N130.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d4(ind):\n",
    "    torch.random.seed()\n",
    "    N=95\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    a = list(range(1,4))\n",
    "    b = list(range(1,4))\n",
    "    c = list(range(1,4))\n",
    "    d = list(range(1,4))\n",
    "    global paramlist;\n",
    "    paramlist = list(itertools.product(a,b,c,d))\n",
    "    \n",
    "    result1 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in paramlist:\n",
    "        result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i[0]]+[i[1]]+[i[2]]+[i[3]]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result)\n",
    "        if result[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "    rBIC = []\n",
    "    rsigma = []\n",
    "    for i in range(len(result1)):\n",
    "        sigma = (np.linalg.norm(Y-result1[i][2]@X)**2)/(Y.shape[1])\n",
    "        a,b,c,d = paramlist[i]\n",
    "        df = 6*(a+d)+6*(a*b+b*c+c*d)+b\n",
    "        BIC = np.log(sigma)+0.02*np.log(Y.shape[1])*(df+1)/(Y.shape[1])\n",
    "        rBIC.append(BIC)\n",
    "        rsigma.append(np.log(sigma))\n",
    "\n",
    "    return (rBIC,paramlist[np.argsort(np.array(rBIC))[0]],t1,t2,rsigma,Y,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [1:13:47<00:00,  8.85s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4429.459269523621\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d4,l),total=500))\n",
    "        with open('N95.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d5(ind):\n",
    "    torch.random.seed()\n",
    "    N=60\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    a = list(range(1,4))\n",
    "    b = list(range(1,4))\n",
    "    c = list(range(1,4))\n",
    "    d = list(range(1,4))\n",
    "    global paramlist;\n",
    "    paramlist = list(itertools.product(a,b,c,d))\n",
    "    \n",
    "    result1 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in paramlist:\n",
    "        result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i[0]]+[i[1]]+[i[2]]+[i[3]]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result)\n",
    "        if result[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "    rBIC = []\n",
    "    rsigma = []\n",
    "    for i in range(len(result1)):\n",
    "        sigma = (np.linalg.norm(Y-result1[i][2]@X)**2)/(Y.shape[1])\n",
    "        a,b,c,d = paramlist[i]\n",
    "        df = 6*(a+d)+6*(a*b+b*c+c*d)+b\n",
    "        BIC = np.log(sigma)+0.02*np.log(Y.shape[1])*(df+1)/(Y.shape[1])\n",
    "        rBIC.append(BIC)\n",
    "        rsigma.append(np.log(sigma))\n",
    "\n",
    "    return (rBIC,paramlist[np.argsort(np.array(rBIC))[0]],t1,t2,rsigma,Y,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [2:45:35<00:00, 19.87s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9938.091502428055\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d5,l),total=500))\n",
    "        with open('N60.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d6(ind):\n",
    "    torch.random.seed()\n",
    "    N=25\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    a = list(range(1,4))\n",
    "    b = list(range(1,4))\n",
    "    c = list(range(1,4))\n",
    "    d = list(range(1,4))\n",
    "    global paramlist;\n",
    "    paramlist = list(itertools.product(a,b,c,d))\n",
    "    \n",
    "    result1 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in paramlist:\n",
    "        result = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i[0]]+[i[1]]+[i[2]]+[i[3]]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result)\n",
    "        if result[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "    rBIC = []\n",
    "    rsigma = []\n",
    "    for i in range(len(result1)):\n",
    "        sigma = (np.linalg.norm(Y-result1[i][2]@X)**2)/(Y.shape[1])\n",
    "        a,b,c,d = paramlist[i]\n",
    "        df = 6*(a+d)+6*(a*b+b*c+c*d)+b\n",
    "        BIC = np.log(sigma)+0.02*np.log(Y.shape[1])*(df+1)/(Y.shape[1])\n",
    "        rBIC.append(BIC)\n",
    "        rsigma.append(np.log(sigma))\n",
    "\n",
    "    return (rBIC,paramlist[np.argsort(np.array(rBIC))[0]],t1,t2,rsigma,Y,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [5:22:45<00:00, 38.73s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19368.279304265976\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d6,l),total=500))\n",
    "        with open('N25.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('N200.pkl','rb') as f:\n",
    "    result = pickle.load(f)\n",
    "list1 = []\n",
    "a1 = 0\n",
    "t1 = []\n",
    "a2 = 0\n",
    "t2 = []\n",
    "a3 = 0\n",
    "total = 0\n",
    "for i in range(len(result)):\n",
    "    total+=1\n",
    "    list1.append(result[i][1])\n",
    "    if list(result[i][1])==[2,2,2,2]:\n",
    "        a1 = a1 + 1\n",
    "    t1.append(result[i][2])\n",
    "    if result[i][2]>0:\n",
    "        a2 = a2 + 1\n",
    "    t2.append(result[i][3])\n",
    "    if result[i][3]>0:\n",
    "        a3 = a3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(a1)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2),\n",
       " (2, 2, 2, 2)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2(ind):\n",
    "    # Step 1 generate G and sigma\n",
    "    # d=3 p1=p2=p3=10 r=(1,2,2,2,2,2,1)\n",
    "    # norm(A)=norm(sigma)=5\n",
    "    # T = [1000,1200,1400,1600,2000]\n",
    "    T=150\n",
    "    p=125\n",
    "    torch.random.seed()       \n",
    "        \n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    global ts; global X; global Y;\n",
    "    #ts = torch.empty((p, T), dtype=torch.float64)\n",
    "    X = torch.empty((p, T), dtype=torch.float64)\n",
    "    Y = torch.empty((p, T), dtype=torch.float64)\n",
    "    X[:,0] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "    #ts[:,0] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "    for s in range(0,T):\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        X = X.numpy()\n",
    "        Y = Y.numpy()\n",
    "        if s!=T-1:\n",
    "            X[:,s+1] = (np.transpose((Y[:,s].reshape(list(reversed(p_vec)),order=\"F\")),[2,1,0])).reshape(p,order=\"F\")\n",
    "        #ts[:,s] = torch.tensor(A_mat) @ ts[:,s-1] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        X = torch.tensor(X)\n",
    "        Y = torch.tensor(Y)\n",
    "        #print(s)\n",
    "    #end = time.time()\n",
    "    #print(end-start)\n",
    "    #ts = ts.nump()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "    \n",
    "    #a = list(range(1,4))\n",
    "    #b = list(range(1,4))\n",
    "    #c = list(range(1,4))\n",
    "    #d = list(range(1,4))\n",
    "    #e = list(range(1,4))\n",
    "    #global paramlist;\n",
    "    #paramlist = list(itertools.product(a,b,c,d,e))\n",
    "    \n",
    "    rmax = 3\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    result3 = []\n",
    "    result4 = []\n",
    "    result5 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in range(1,4):\n",
    "        result1a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[i]+[rmax,rmax,rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result1.append(result1a)\n",
    "        if result1a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result1a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result2a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax]+[i]+[rmax,rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result2.append(result2a)\n",
    "        if result2a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result2a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result3a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax]+[i]+[rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result3.append(result3a)\n",
    "        if result3a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result3a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result4a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax,rmax]+[i]+[rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result4.append(result4a)\n",
    "        if result4a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result4a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result5a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax,rmax,rmax]+[i], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result5.append(result5a)\n",
    "        if result5a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result5a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        \n",
    "    rBIC1 = []\n",
    "    rBIC2 = []\n",
    "    rBIC3 = []\n",
    "    rBIC4 = []\n",
    "    rBIC5 = []\n",
    "    for i in range(1,4):\n",
    "        sigma1 = (np.linalg.norm(Y-result1[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a1,b1,c1,d1,e1 = (i,rmax,rmax,rmax,rmax)\n",
    "        df1 = 5*(a1+e1)+5*(a1*b1+b1*c1+c1*d1+d1*e1)+c1\n",
    "        BIC1 = np.log(sigma1)+0.02*np.log(Y.shape[1])*(df1+1)/(Y.shape[1])\n",
    "        rBIC1.append(BIC1)\n",
    "        \n",
    "        sigma2 = (np.linalg.norm(Y-result2[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a2,b2,c2,d2,e2 = (rmax,i,rmax,rmax,rmax)\n",
    "        df2 = 5*(a2+e2)+5*(a2*b2+b2*c2+c2*d2+d2*e2)+c2\n",
    "        BIC2 = np.log(sigma2)+0.02*np.log(Y.shape[1])*(df2+1)/(Y.shape[1])\n",
    "        rBIC2.append(BIC2) \n",
    "        \n",
    "        sigma3 = (np.linalg.norm(Y-result3[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a3,b3,c3,d3,e3 = (rmax,rmax,i,rmax,rmax)\n",
    "        df3 = 5*(a3+e3)+5*(a3*b3+b3*c3+c3*d3+d3*e3)+c3\n",
    "        BIC3 = np.log(sigma3)+0.02*np.log(Y.shape[1])*(df3+1)/(Y.shape[1])\n",
    "        rBIC3.append(BIC3) \n",
    "        \n",
    "        sigma4 = (np.linalg.norm(Y-result4[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a4,b4,c4,d4,e4 = (rmax,rmax,rmax,i,rmax)\n",
    "        df4 = 5*(a4+e4)+5*(a4*b4+b4*c4+c4*d4+d4*e4)+c4\n",
    "        BIC4 = np.log(sigma4)+0.02*np.log(Y.shape[1])*(df4+1)/(Y.shape[1])\n",
    "        rBIC4.append(BIC4) \n",
    "        \n",
    "        sigma5 = (np.linalg.norm(Y-result5[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a5,b5,c5,d5,e5 = (rmax,rmax,rmax,rmax,i)\n",
    "        df5 = 5*(a5+e5)+5*(a5*b5+b5*c5+c5*d5+d5*e5)+c5\n",
    "        BIC5 = np.log(sigma5)+0.02*np.log(Y.shape[1])*(df5+1)/(Y.shape[1])\n",
    "        rBIC5.append(BIC5) \n",
    "        \n",
    "    est_rank = [np.argsort(np.array(rBIC1))[0]+1]+[np.argsort(np.array(rBIC2))[0]+1]+[np.argsort(np.array(rBIC3))[0]+1]+[np.argsort(np.array(rBIC4))[0]+1]+[np.argsort(np.array(rBIC5))[0]+1]\n",
    "    rBIC = rBIC1 + rBIC2 + rBIC3 +rBIC4 + rBIC5\n",
    "\n",
    "    return (rBIC,est_rank,t1,t2)\n",
    "    #return (X,Y,A_mat,A_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d3(ind):\n",
    "    # Step 1 generate G and sigma\n",
    "    # d=3 p1=p2=p3=10 r=(1,2,2,2,2,2,1)\n",
    "    # norm(A)=norm(sigma)=5\n",
    "    # T = [1000,1200,1400,1600,2000]\n",
    "    T=250\n",
    "    p=125\n",
    "    torch.random.seed()       \n",
    "        \n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    global ts; global X; global Y;\n",
    "    #ts = torch.empty((p, T), dtype=torch.float64)\n",
    "    X = torch.empty((p, T), dtype=torch.float64)\n",
    "    Y = torch.empty((p, T), dtype=torch.float64)\n",
    "    X[:,0] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "    #ts[:,0] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "    for s in range(0,T):\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        X = X.numpy()\n",
    "        Y = Y.numpy()\n",
    "        if s!=T-1:\n",
    "            X[:,s+1] = (np.transpose((Y[:,s].reshape(list(reversed(p_vec)),order=\"F\")),[2,1,0])).reshape(p,order=\"F\")\n",
    "        #ts[:,s] = torch.tensor(A_mat) @ ts[:,s-1] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        X = torch.tensor(X)\n",
    "        Y = torch.tensor(Y)\n",
    "        #print(s)\n",
    "    #end = time.time()\n",
    "    #print(end-start)\n",
    "    #ts = ts.nump()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "    \n",
    "    #a = list(range(1,4))\n",
    "    #b = list(range(1,4))\n",
    "    #c = list(range(1,4))\n",
    "    #d = list(range(1,4))\n",
    "    #e = list(range(1,4))\n",
    "    #global paramlist;\n",
    "    #paramlist = list(itertools.product(a,b,c,d,e))\n",
    "    \n",
    "    rmax = 3\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    result3 = []\n",
    "    result4 = []\n",
    "    result5 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in range(1,4):\n",
    "        result1a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[i]+[rmax,rmax,rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result1.append(result1a)\n",
    "        if result1a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result1a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result2a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax]+[i]+[rmax,rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result2.append(result2a)\n",
    "        if result2a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result2a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result3a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax]+[i]+[rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result3.append(result3a)\n",
    "        if result3a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result3a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result4a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax,rmax]+[i]+[rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result4.append(result4a)\n",
    "        if result4a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result4a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result5a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax,rmax,rmax]+[i], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result5.append(result5a)\n",
    "        if result5a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result5a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        \n",
    "    rBIC1 = []\n",
    "    rBIC2 = []\n",
    "    rBIC3 = []\n",
    "    rBIC4 = []\n",
    "    rBIC5 = []\n",
    "    for i in range(1,4):\n",
    "        sigma1 = (np.linalg.norm(Y-result1[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a1,b1,c1,d1,e1 = (i,rmax,rmax,rmax,rmax)\n",
    "        df1 = 5*(a1+e1)+5*(a1*b1+b1*c1+c1*d1+d1*e1)+c1\n",
    "        BIC1 = np.log(sigma1)+0.02*np.log(Y.shape[1])*(df1+1)/(Y.shape[1])\n",
    "        rBIC1.append(BIC1)\n",
    "        \n",
    "        sigma2 = (np.linalg.norm(Y-result2[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a2,b2,c2,d2,e2 = (rmax,i,rmax,rmax,rmax)\n",
    "        df2 = 5*(a2+e2)+5*(a2*b2+b2*c2+c2*d2+d2*e2)+c2\n",
    "        BIC2 = np.log(sigma2)+0.02*np.log(Y.shape[1])*(df2+1)/(Y.shape[1])\n",
    "        rBIC2.append(BIC2) \n",
    "        \n",
    "        sigma3 = (np.linalg.norm(Y-result3[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a3,b3,c3,d3,e3 = (rmax,rmax,i,rmax,rmax)\n",
    "        df3 = 5*(a3+e3)+5*(a3*b3+b3*c3+c3*d3+d3*e3)+c3\n",
    "        BIC3 = np.log(sigma3)+0.02*np.log(Y.shape[1])*(df3+1)/(Y.shape[1])\n",
    "        rBIC3.append(BIC3) \n",
    "        \n",
    "        sigma4 = (np.linalg.norm(Y-result4[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a4,b4,c4,d4,e4 = (rmax,rmax,rmax,i,rmax)\n",
    "        df4 = 5*(a4+e4)+5*(a4*b4+b4*c4+c4*d4+d4*e4)+c4\n",
    "        BIC4 = np.log(sigma4)+0.02*np.log(Y.shape[1])*(df4+1)/(Y.shape[1])\n",
    "        rBIC4.append(BIC4) \n",
    "        \n",
    "        sigma5 = (np.linalg.norm(Y-result5[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a5,b5,c5,d5,e5 = (rmax,rmax,rmax,rmax,i)\n",
    "        df5 = 5*(a5+e5)+5*(a5*b5+b5*c5+c5*d5+d5*e5)+c5\n",
    "        BIC5 = np.log(sigma5)+0.02*np.log(Y.shape[1])*(df5+1)/(Y.shape[1])\n",
    "        rBIC5.append(BIC5) \n",
    "        \n",
    "    est_rank = [np.argsort(np.array(rBIC1))[0]+1]+[np.argsort(np.array(rBIC2))[0]+1]+[np.argsort(np.array(rBIC3))[0]+1]+[np.argsort(np.array(rBIC4))[0]+1]+[np.argsort(np.array(rBIC5))[0]+1]\n",
    "    rBIC = rBIC1 + rBIC2 + rBIC3 +rBIC4 + rBIC5\n",
    "\n",
    "    return (rBIC,est_rank,t1,t2)\n",
    "    #return (X,Y,A_mat,A_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d4(ind):\n",
    "    # Step 1 generate G and sigma\n",
    "    # d=3 p1=p2=p3=10 r=(1,2,2,2,2,2,1)\n",
    "    # norm(A)=norm(sigma)=5\n",
    "    # T = [1000,1200,1400,1600,2000]\n",
    "    T=350\n",
    "    p = 125\n",
    "    torch.random.seed()       \n",
    "        \n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    global ts; global X; global Y;\n",
    "    #ts = torch.empty((p, T), dtype=torch.float64)\n",
    "    X = torch.empty((p, T), dtype=torch.float64)\n",
    "    Y = torch.empty((p, T), dtype=torch.float64)\n",
    "    X[:,0] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "    #ts[:,0] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "    for s in range(0,T):\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        X = X.numpy()\n",
    "        Y = Y.numpy()\n",
    "        if s!=T-1:\n",
    "            X[:,s+1] = (np.transpose((Y[:,s].reshape(list(reversed(p_vec)),order=\"F\")),[2,1,0])).reshape(p,order=\"F\")\n",
    "        #ts[:,s] = torch.tensor(A_mat) @ ts[:,s-1] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        X = torch.tensor(X)\n",
    "        Y = torch.tensor(Y)\n",
    "        #print(s)\n",
    "    #end = time.time()\n",
    "    #print(end-start)\n",
    "    #ts = ts.nump()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "    \n",
    "    #a = list(range(1,4))\n",
    "    #b = list(range(1,4))\n",
    "    #c = list(range(1,4))\n",
    "    #d = list(range(1,4))\n",
    "    #e = list(range(1,4))\n",
    "    #global paramlist;\n",
    "    #paramlist = list(itertools.product(a,b,c,d,e))\n",
    "    \n",
    "    rmax = 3\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    result3 = []\n",
    "    result4 = []\n",
    "    result5 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in range(1,4):\n",
    "        result1a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[i]+[rmax,rmax,rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result1.append(result1a)\n",
    "        if result1a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result1a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result2a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax]+[i]+[rmax,rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result2.append(result2a)\n",
    "        if result2a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result2a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result3a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax]+[i]+[rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result3.append(result3a)\n",
    "        if result3a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result3a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result4a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax,rmax]+[i]+[rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result4.append(result4a)\n",
    "        if result4a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result4a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result5a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax,rmax,rmax]+[i], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result5.append(result5a)\n",
    "        if result5a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result5a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        \n",
    "    rBIC1 = []\n",
    "    rBIC2 = []\n",
    "    rBIC3 = []\n",
    "    rBIC4 = []\n",
    "    rBIC5 = []\n",
    "    for i in range(1,4):\n",
    "        sigma1 = (np.linalg.norm(Y-result1[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a1,b1,c1,d1,e1 = (i,rmax,rmax,rmax,rmax)\n",
    "        df1 = 5*(a1+e1)+5*(a1*b1+b1*c1+c1*d1+d1*e1)+c1\n",
    "        BIC1 = np.log(sigma1)+0.02*np.log(Y.shape[1])*(df1+1)/(Y.shape[1])\n",
    "        rBIC1.append(BIC1)\n",
    "        \n",
    "        sigma2 = (np.linalg.norm(Y-result2[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a2,b2,c2,d2,e2 = (rmax,i,rmax,rmax,rmax)\n",
    "        df2 = 5*(a2+e2)+5*(a2*b2+b2*c2+c2*d2+d2*e2)+c2\n",
    "        BIC2 = np.log(sigma2)+0.02*np.log(Y.shape[1])*(df2+1)/(Y.shape[1])\n",
    "        rBIC2.append(BIC2) \n",
    "        \n",
    "        sigma3 = (np.linalg.norm(Y-result3[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a3,b3,c3,d3,e3 = (rmax,rmax,i,rmax,rmax)\n",
    "        df3 = 5*(a3+e3)+5*(a3*b3+b3*c3+c3*d3+d3*e3)+c3\n",
    "        BIC3 = np.log(sigma3)+0.02*np.log(Y.shape[1])*(df3+1)/(Y.shape[1])\n",
    "        rBIC3.append(BIC3) \n",
    "        \n",
    "        sigma4 = (np.linalg.norm(Y-result4[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a4,b4,c4,d4,e4 = (rmax,rmax,rmax,i,rmax)\n",
    "        df4 = 5*(a4+e4)+5*(a4*b4+b4*c4+c4*d4+d4*e4)+c4\n",
    "        BIC4 = np.log(sigma4)+0.02*np.log(Y.shape[1])*(df4+1)/(Y.shape[1])\n",
    "        rBIC4.append(BIC4) \n",
    "        \n",
    "        sigma5 = (np.linalg.norm(Y-result5[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a5,b5,c5,d5,e5 = (rmax,rmax,rmax,rmax,i)\n",
    "        df5 = 5*(a5+e5)+5*(a5*b5+b5*c5+c5*d5+d5*e5)+c5\n",
    "        BIC5 = np.log(sigma5)+0.02*np.log(Y.shape[1])*(df5+1)/(Y.shape[1])\n",
    "        rBIC5.append(BIC5) \n",
    "        \n",
    "    est_rank = [np.argsort(np.array(rBIC1))[0]+1]+[np.argsort(np.array(rBIC2))[0]+1]+[np.argsort(np.array(rBIC3))[0]+1]+[np.argsort(np.array(rBIC4))[0]+1]+[np.argsort(np.array(rBIC5))[0]+1]\n",
    "    rBIC = rBIC1 + rBIC2 + rBIC3 +rBIC4 + rBIC5\n",
    "\n",
    "    return (rBIC,est_rank,t1,t2)\n",
    "    #return (X,Y,A_mat,A_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d5(ind):\n",
    "    # Step 1 generate G and sigma\n",
    "    # d=3 p1=p2=p3=10 r=(1,2,2,2,2,2,1)\n",
    "    # norm(A)=norm(sigma)=5\n",
    "    # T = [1000,1200,1400,1600,2000]\n",
    "    T=450\n",
    "    p = 125\n",
    "    torch.random.seed()       \n",
    "        \n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    global ts; global X; global Y;\n",
    "    #ts = torch.empty((p, T), dtype=torch.float64)\n",
    "    X = torch.empty((p, T), dtype=torch.float64)\n",
    "    Y = torch.empty((p, T), dtype=torch.float64)\n",
    "    X[:,0] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "    #ts[:,0] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "    for s in range(0,T):\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        X = X.numpy()\n",
    "        Y = Y.numpy()\n",
    "        if s!=T-1:\n",
    "            X[:,s+1] = (np.transpose((Y[:,s].reshape(list(reversed(p_vec)),order=\"F\")),[2,1,0])).reshape(p,order=\"F\")\n",
    "        #ts[:,s] = torch.tensor(A_mat) @ ts[:,s-1] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        X = torch.tensor(X)\n",
    "        Y = torch.tensor(Y)\n",
    "        #print(s)\n",
    "    #end = time.time()\n",
    "    #print(end-start)\n",
    "    #ts = ts.nump()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "    \n",
    "    #a = list(range(1,4))\n",
    "    #b = list(range(1,4))\n",
    "    #c = list(range(1,4))\n",
    "    #d = list(range(1,4))\n",
    "    #e = list(range(1,4))\n",
    "    #global paramlist;\n",
    "    #paramlist = list(itertools.product(a,b,c,d,e))\n",
    "    \n",
    "    rmax = 3\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    result3 = []\n",
    "    result4 = []\n",
    "    result5 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in range(1,4):\n",
    "        result1a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[i]+[rmax,rmax,rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result1.append(result1a)\n",
    "        if result1a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result1a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result2a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax]+[i]+[rmax,rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result2.append(result2a)\n",
    "        if result2a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result2a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result3a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax]+[i]+[rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result3.append(result3a)\n",
    "        if result3a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result3a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result4a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax,rmax]+[i]+[rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result4.append(result4a)\n",
    "        if result4a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result4a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result5a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax,rmax,rmax]+[i], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result5.append(result5a)\n",
    "        if result5a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result5a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        \n",
    "    rBIC1 = []\n",
    "    rBIC2 = []\n",
    "    rBIC3 = []\n",
    "    rBIC4 = []\n",
    "    rBIC5 = []\n",
    "    for i in range(1,4):\n",
    "        sigma1 = (np.linalg.norm(Y-result1[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a1,b1,c1,d1,e1 = (i,rmax,rmax,rmax,rmax)\n",
    "        df1 = 5*(a1+e1)+5*(a1*b1+b1*c1+c1*d1+d1*e1)+c1\n",
    "        BIC1 = np.log(sigma1)+0.02*np.log(Y.shape[1])*(df1+1)/(Y.shape[1])\n",
    "        rBIC1.append(BIC1)\n",
    "        \n",
    "        sigma2 = (np.linalg.norm(Y-result2[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a2,b2,c2,d2,e2 = (rmax,i,rmax,rmax,rmax)\n",
    "        df2 = 5*(a2+e2)+5*(a2*b2+b2*c2+c2*d2+d2*e2)+c2\n",
    "        BIC2 = np.log(sigma2)+0.02*np.log(Y.shape[1])*(df2+1)/(Y.shape[1])\n",
    "        rBIC2.append(BIC2) \n",
    "        \n",
    "        sigma3 = (np.linalg.norm(Y-result3[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a3,b3,c3,d3,e3 = (rmax,rmax,i,rmax,rmax)\n",
    "        df3 = 5*(a3+e3)+5*(a3*b3+b3*c3+c3*d3+d3*e3)+c3\n",
    "        BIC3 = np.log(sigma3)+0.02*np.log(Y.shape[1])*(df3+1)/(Y.shape[1])\n",
    "        rBIC3.append(BIC3) \n",
    "        \n",
    "        sigma4 = (np.linalg.norm(Y-result4[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a4,b4,c4,d4,e4 = (rmax,rmax,rmax,i,rmax)\n",
    "        df4 = 5*(a4+e4)+5*(a4*b4+b4*c4+c4*d4+d4*e4)+c4\n",
    "        BIC4 = np.log(sigma4)+0.02*np.log(Y.shape[1])*(df4+1)/(Y.shape[1])\n",
    "        rBIC4.append(BIC4) \n",
    "        \n",
    "        sigma5 = (np.linalg.norm(Y-result5[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a5,b5,c5,d5,e5 = (rmax,rmax,rmax,rmax,i)\n",
    "        df5 = 5*(a5+e5)+5*(a5*b5+b5*c5+c5*d5+d5*e5)+c5\n",
    "        BIC5 = np.log(sigma5)+0.02*np.log(Y.shape[1])*(df5+1)/(Y.shape[1])\n",
    "        rBIC5.append(BIC5) \n",
    "        \n",
    "    est_rank = [np.argsort(np.array(rBIC1))[0]+1]+[np.argsort(np.array(rBIC2))[0]+1]+[np.argsort(np.array(rBIC3))[0]+1]+[np.argsort(np.array(rBIC4))[0]+1]+[np.argsort(np.array(rBIC5))[0]+1]\n",
    "    rBIC = rBIC1 + rBIC2 + rBIC3 +rBIC4 + rBIC5\n",
    "\n",
    "    return (rBIC,est_rank,t1,t2)\n",
    "    #return (X,Y,A_mat,A_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d6(ind):\n",
    "    # Step 1 generate G and sigma\n",
    "    # d=3 p1=p2=p3=10 r=(1,2,2,2,2,2,1)\n",
    "    # norm(A)=norm(sigma)=5\n",
    "    # T = [1000,1200,1400,1600,2000]\n",
    "    T=550\n",
    "    p = 125\n",
    "    torch.random.seed()       \n",
    "        \n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    global ts; global X; global Y;\n",
    "    #ts = torch.empty((p, T), dtype=torch.float64)\n",
    "    X = torch.empty((p, T), dtype=torch.float64)\n",
    "    Y = torch.empty((p, T), dtype=torch.float64)\n",
    "    X[:,0] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "    #ts[:,0] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "    for s in range(0,T):\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        X = X.numpy()\n",
    "        Y = Y.numpy()\n",
    "        if s!=T-1:\n",
    "            X[:,s+1] = (np.transpose((Y[:,s].reshape(list(reversed(p_vec)),order=\"F\")),[2,1,0])).reshape(p,order=\"F\")\n",
    "        #ts[:,s] = torch.tensor(A_mat) @ ts[:,s-1] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        X = torch.tensor(X)\n",
    "        Y = torch.tensor(Y)\n",
    "        #print(s)\n",
    "    #end = time.time()\n",
    "    #print(end-start)\n",
    "    #ts = ts.nump()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "    \n",
    "    #a = list(range(1,4))\n",
    "    #b = list(range(1,4))\n",
    "    #c = list(range(1,4))\n",
    "    #d = list(range(1,4))\n",
    "    #e = list(range(1,4))\n",
    "    #global paramlist;\n",
    "    #paramlist = list(itertools.product(a,b,c,d,e))\n",
    "    \n",
    "    rmax = 3\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    result3 = []\n",
    "    result4 = []\n",
    "    result5 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in range(1,4):\n",
    "        result1a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[i]+[rmax,rmax,rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result1.append(result1a)\n",
    "        if result1a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result1a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result2a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax]+[i]+[rmax,rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result2.append(result2a)\n",
    "        if result2a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result2a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result3a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax]+[i]+[rmax,rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result3.append(result3a)\n",
    "        if result3a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result3a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result4a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax,rmax]+[i]+[rmax], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result4.append(result4a)\n",
    "        if result4a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result4a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result5a = PGD(Y, X, trueA=A_mat, p_vec=p_vec, mtl_rank=[rmax,rmax,rmax,rmax]+[i], eta=0.01, max_iter=2000, tol=1e-4)\n",
    "        result5.append(result5a)\n",
    "        if result5a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result5a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        \n",
    "    rBIC1 = []\n",
    "    rBIC2 = []\n",
    "    rBIC3 = []\n",
    "    rBIC4 = []\n",
    "    rBIC5 = []\n",
    "    for i in range(1,4):\n",
    "        sigma1 = (np.linalg.norm(Y-result1[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a1,b1,c1,d1,e1 = (i,rmax,rmax,rmax,rmax)\n",
    "        df1 = 5*(a1+e1)+5*(a1*b1+b1*c1+c1*d1+d1*e1)+c1\n",
    "        BIC1 = np.log(sigma1)+0.02*np.log(Y.shape[1])*(df1+1)/(Y.shape[1])\n",
    "        rBIC1.append(BIC1)\n",
    "        \n",
    "        sigma2 = (np.linalg.norm(Y-result2[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a2,b2,c2,d2,e2 = (rmax,i,rmax,rmax,rmax)\n",
    "        df2 = 5*(a2+e2)+5*(a2*b2+b2*c2+c2*d2+d2*e2)+c2\n",
    "        BIC2 = np.log(sigma2)+0.02*np.log(Y.shape[1])*(df2+1)/(Y.shape[1])\n",
    "        rBIC2.append(BIC2) \n",
    "        \n",
    "        sigma3 = (np.linalg.norm(Y-result3[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a3,b3,c3,d3,e3 = (rmax,rmax,i,rmax,rmax)\n",
    "        df3 = 5*(a3+e3)+5*(a3*b3+b3*c3+c3*d3+d3*e3)+c3\n",
    "        BIC3 = np.log(sigma3)+0.02*np.log(Y.shape[1])*(df3+1)/(Y.shape[1])\n",
    "        rBIC3.append(BIC3) \n",
    "        \n",
    "        sigma4 = (np.linalg.norm(Y-result4[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a4,b4,c4,d4,e4 = (rmax,rmax,rmax,i,rmax)\n",
    "        df4 = 5*(a4+e4)+5*(a4*b4+b4*c4+c4*d4+d4*e4)+c4\n",
    "        BIC4 = np.log(sigma4)+0.02*np.log(Y.shape[1])*(df4+1)/(Y.shape[1])\n",
    "        rBIC4.append(BIC4) \n",
    "        \n",
    "        sigma5 = (np.linalg.norm(Y-result5[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a5,b5,c5,d5,e5 = (rmax,rmax,rmax,rmax,i)\n",
    "        df5 = 5*(a5+e5)+5*(a5*b5+b5*c5+c5*d5+d5*e5)+c5\n",
    "        BIC5 = np.log(sigma5)+0.02*np.log(Y.shape[1])*(df5+1)/(Y.shape[1])\n",
    "        rBIC5.append(BIC5) \n",
    "        \n",
    "    est_rank = [np.argsort(np.array(rBIC1))[0]+1]+[np.argsort(np.array(rBIC2))[0]+1]+[np.argsort(np.array(rBIC3))[0]+1]+[np.argsort(np.array(rBIC4))[0]+1]+[np.argsort(np.array(rBIC5))[0]+1]\n",
    "    rBIC = rBIC1 + rBIC2 + rBIC3 +rBIC4 + rBIC5\n",
    "\n",
    "    return (rBIC,est_rank,t1,t2)\n",
    "    #return (X,Y,A_mat,A_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(470))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d1,l),total=470))\n",
    "        with open('33seprselectT50p5R2part2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(470))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d2,l),total=470))\n",
    "        with open('33seprselectT150p5R2part2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(470))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d3,l),total=470))\n",
    "        with open('33seprselectT250p5R2part2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(470))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d4,l),total=470))\n",
    "        with open('33seprselectT350p5R2part2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(470))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d5,l),total=470))\n",
    "        with open('33seprselectT450p5R2part2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d6,l),total=500))\n",
    "        with open('33seprselectT550p5R2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vec=[5,5,5]\n",
    "mtl_rank = [1,2,2,2,2,2,1]\n",
    "import pickle\n",
    "with open('/home/r11user2/Documents/YF/TT_decomposition/seprank_selection/sigma42/42sepAp5r2.pkl','rb') as f:\n",
    "    A_mat, A_ts, _ = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1=np.linalg.svd(A_ts.reshape(5,25*125,order=\"F\"))[1][:2]\n",
    "lambda2=np.linalg.svd(A_ts.reshape(25,5*125,order=\"F\"))[1][:2]\n",
    "lambda3=np.linalg.svd(A_ts.reshape(125,125,order=\"F\"))[1][:2]\n",
    "lambda4=np.linalg.svd(A_ts.reshape(125*5,25,order=\"F\"))[1][:2]\n",
    "lambda5=np.linalg.svd(A_ts.reshape(125*25,5,order=\"F\"))[1][:2]\n",
    "lambdatotal=np.concatenate((lambda1,lambda2,lambda3,lambda4,lambda5))\n",
    "np.min(lambdatotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(470))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d1,l),total=470))\n",
    "        with open('42seprselectT50p5R2part2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(470))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d2,l),total=470))\n",
    "        with open('42seprselectT150p5R2part2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(470))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d3,l),total=470))\n",
    "        with open('42seprselectT250p5R2part2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(470))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d4,l),total=470))\n",
    "        with open('42seprselectT350p5R2part2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(470))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d5,l),total=470))\n",
    "        with open('42seprselectT450p5R2part2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d6,l),total=500))\n",
    "        with open('42seprselectT550p5R2.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vec=[5,5,5]\n",
    "p = np.prod(p_vec)\n",
    "mtl_rank = [1,2,2,2,2,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global stationary\n",
    "p_vec=[5,5,5]\n",
    "p = np.prod(p_vec)\n",
    "mtl_rank = [1,2,2,2,2,2,1]\n",
    "stationary = False\n",
    "while not stationary:\n",
    "    global G1; global G2; global G3; global sigma; global G4; global G5; global G6;\n",
    "    global A_ts; global A_mat\n",
    "    G1 = np.linalg.svd(np.random.normal(0,1,p_vec[2]*p_vec[2]).reshape(p_vec[2],p_vec[2]))[0][:,0:mtl_rank[1]].reshape(mtl_rank[0],p_vec[2],mtl_rank[1],order=\"F\")\n",
    "    G2 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[1]*mtl_rank[1])).reshape(p_vec[1]*mtl_rank[1],p_vec[1]*mtl_rank[1]))[0][:,0:mtl_rank[2]].reshape(mtl_rank[1],p_vec[1],mtl_rank[2],order=\"F\")\n",
    "    G3 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[0]*mtl_rank[2])).reshape(p_vec[0]*mtl_rank[2],p_vec[0]*mtl_rank[2]))[0][:,0:mtl_rank[3]].reshape(mtl_rank[2],p_vec[0],mtl_rank[3],order=\"F\")\n",
    "    sigma = np.diag([1.5,1.5])\n",
    "    G4 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[0]*mtl_rank[4])).reshape(p_vec[0]*mtl_rank[4],p_vec[0]*mtl_rank[4]))[2][0:mtl_rank[3],:].reshape(mtl_rank[3],p_vec[0],mtl_rank[4],order=\"F\")\n",
    "    G5 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[1]*mtl_rank[5])).reshape(p_vec[1]*mtl_rank[5],p_vec[1]*mtl_rank[5]))[2][0:mtl_rank[4],:].reshape(mtl_rank[4],p_vec[1],mtl_rank[5],order=\"F\")\n",
    "    G6 = np.linalg.svd(np.random.normal(0,1,p_vec[2]*p_vec[2]).reshape(p_vec[2],p_vec[2]))[2][0:mtl_rank[5],:].reshape(mtl_rank[5],p_vec[2],mtl_rank[6],order=\"F\")\n",
    "    A_ts = core_to_tensor([G1,G2,G3,sigma,G4,G5,G6], list(reversed(p_vec))+p_vec)\n",
    "    A_mat = A_ts.reshape(p, p, order=\"F\")\n",
    "    A_ts1 = np.transpose(A_ts,[2,1,0,3,4,5])\n",
    "    stationary = np.max(np.abs(np.linalg.eig(A_mat)[0])) < 1 and np.max(np.abs(np.linalg.eig(A_ts1.reshape(p,p,order=\"F\"))[0])) < 1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ts = res[1]\n",
    "lambda1=np.linalg.svd(A_ts.reshape(5,25*125,order=\"F\"))[1][:2]\n",
    "lambda2=np.linalg.svd(A_ts.reshape(25,5*125,order=\"F\"))[1][:2]\n",
    "lambda3=np.linalg.svd(A_ts.reshape(125,125,order=\"F\"))[1][:2]\n",
    "lambda4=np.linalg.svd(A_ts.reshape(125*5,25,order=\"F\"))[1][:2]\n",
    "lambda5=np.linalg.svd(A_ts.reshape(125*25,5,order=\"F\"))[1][:2]\n",
    "lambdatotal=np.concatenate((lambda1,lambda2,lambda3,lambda4,lambda5))\n",
    "np.min(lambdatotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(A_mat,\"f\")**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('1515sepAp5r2.pkl','wb') as f:\n",
    "    pickle.dump([A_mat, A_ts, A_ts1], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('1515sepAp5r2.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "A_mat = res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d1,l),total=300))\n",
    "        with open('11seprselectT50p5R2part1.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d2,l),total=300))\n",
    "        with open('11seprselectT150p5R2part1.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d3,l),total=300))\n",
    "        with open('11seprselectT250p5R2part1.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d4,l),total=300))\n",
    "        with open('11seprselectT350p5R2part1.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(300))\n",
    "    with Pool(30) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d5,l),total=300))\n",
    "        with open('11seprselectT450p5R2part1.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('seprselectT1000p5R2.pkl','rb') as f:\n",
    "    result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "a1 = 0\n",
    "t1 = []\n",
    "a2 = 0\n",
    "t2 = []\n",
    "a3 = 0\n",
    "for i in range(len(result)):\n",
    "    list1.append(result[i][1])\n",
    "    if result[i][1]==[2,2,2,2,2]:\n",
    "        a1 = a1 + 1\n",
    "    t1.append(result[i][2])\n",
    "    if result[i][2]>0:\n",
    "        a2 = a2 + 1\n",
    "    t2.append(result[i][3])\n",
    "    if result[i][3]>0:\n",
    "        a3 = a3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
