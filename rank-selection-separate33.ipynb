{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=1\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=1\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=1\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=1\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "from tensorly import tt_to_tensor\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch\n",
    "from multiprocessing import Pool\n",
    "import scipy\n",
    "from tensorly.tenalg import contract\n",
    "import pickle\n",
    "import itertools\n",
    "import scipy\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensordot(A,B,modes):\n",
    "    return contract(A,modes[0],B,modes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TTOI(Y_tensor, r_vec, iter, tol):\n",
    "    dim_vec = Y_tensor.shape\n",
    "    d = len(dim_vec)\n",
    "    X_hat_arr = [None] * iter\n",
    "    V_prod_arr = [None] * int(np.floor(iter/2)+1)\n",
    "    U_prod_arr = [None] * int(np.ceil(iter/2))\n",
    "    Y_arr = [None] * (d-1)\n",
    "    for i in range(d-1):\n",
    "        Y_arr[i] = Y_tensor.reshape(np.prod(dim_vec[:i+1]), np.prod(dim_vec[i+1:]), order=\"F\")\n",
    "    V_prod_arr[0] = [1] * (d-1)\n",
    "    n = 0\n",
    "    chg = np.Inf\n",
    "    while n<iter and chg > tol:\n",
    "        if n==0:\n",
    "            U_prod_arr[int(n / 2)] = [None] * (d - 1)\n",
    "            Y_tilde_arr = [None] * (d - 2)\n",
    "            U_temp, _, _ = np.linalg.svd(Y_arr[0])\n",
    "            U_temp = U_temp[:, :r_vec[0]]\n",
    "            U_prod_arr[int(n / 2)][0] = U_temp\n",
    "            for k in range(1, d - 1):\n",
    "                Y_temp = np.kron(np.eye(dim_vec[k]), U_prod_arr[int(n / 2)][k - 1]).T @ Y_arr[k]\n",
    "                Y_tilde_arr[k - 1] = Y_temp.reshape(r_vec[k - 1], np.prod(dim_vec[k:]), order=\"F\")\n",
    "                U_temp, _, _ = np.linalg.svd(Y_temp)\n",
    "                U_temp = U_temp[:, :r_vec[k]]\n",
    "                U_prod_arr[int(n / 2)][k] = np.kron(np.eye(dim_vec[k]), U_prod_arr[int(n / 2)][k - 1]) @ U_temp\n",
    "            X_hat_temp = U_prod_arr[int(n / 2)][d - 2].T @ Y_arr[d - 2]\n",
    "            X_hat_arr[n] = (U_prod_arr[int(n / 2)][d - 2] @ X_hat_temp).reshape(dim_vec, order=\"F\")\n",
    "        elif n % 2 == 0:\n",
    "            U_prod_arr[int(n/2)] = [None] * (d-1)\n",
    "            Y_tilde_arr = [None] * (d-2)\n",
    "            U_temp, _, _ = np.linalg.svd(Y_arr[0]@V_prod_arr[int(n/2)][d-2])\n",
    "            U_temp = U_temp[:,:r_vec[0]]\n",
    "            U_prod_arr[int(n/2)][0] = U_temp\n",
    "            for k in range(1,d-1):\n",
    "                Y_temp = np.kron(np.eye(dim_vec[k]),U_prod_arr[int(n/2)][k-1]).T@Y_arr[k]\n",
    "                Y_tilde_arr[k-1] = Y_temp.reshape(r_vec[k-1],np.prod(dim_vec[k:]),order=\"F\")\n",
    "                U_temp, _, _ = np.linalg.svd(Y_temp@V_prod_arr[int(n/2)][d-k-2])\n",
    "                U_temp = U_temp[:,:r_vec[k]]\n",
    "                U_prod_arr[int(n/2)][k] = np.kron(np.eye(dim_vec[k]),U_prod_arr[int(n/2)][k-1])@U_temp\n",
    "            X_hat_temp = U_prod_arr[int(n/2)][d-2].T@Y_arr[d-2]\n",
    "            X_hat_arr[n] = (U_prod_arr[int(n/2)][d-2]@X_hat_temp).reshape(dim_vec,order=\"F\")\n",
    "        else:\n",
    "            V_prod_arr[int((n+1)/2)] = [None] * (d-1)\n",
    "            _, _, V_temp = np.linalg.svd(U_prod_arr[int((n-1)/2)][d-2].T@Y_arr[d-2])\n",
    "            V_temp = V_temp[:r_vec[d-2],:].T\n",
    "            V_prod_arr[int((n+1)/2)][0] = V_temp\n",
    "            for k in range(1,d-1):\n",
    "                _, _, V_temp = np.linalg.svd(Y_tilde_arr[d-k-2]@np.kron(V_prod_arr[int((n+1)/2)][k-1],np.eye(dim_vec[d-k-1])))\n",
    "                V_temp = V_temp[:r_vec[d - k-2], :].T\n",
    "                V_prod_arr[int((n+1)/2)][k] = np.kron(V_prod_arr[int((n+1)/2)][k-1],np.eye(dim_vec[d-k-1]))@V_temp\n",
    "            X_hat_temp = Y_arr[0]@V_prod_arr[int((n+1)/2)][d-2]\n",
    "            X_hat_arr[n] = (X_hat_temp@V_prod_arr[int((n+1)/2)][d-2].T).reshape(dim_vec,order=\"F\")\n",
    "        n=n+1\n",
    "        if n>1:\n",
    "            chg = np.square(np.linalg.norm(X_hat_arr[n-1].reshape(np.prod(dim_vec),1),\"fro\"))-np.square(np.linalg.norm(X_hat_arr[n-2].reshape(np.prod(dim_vec),1),\"fro\"))\n",
    "\n",
    "    return [x for x in X_hat_arr if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGrad5(X, ranks, A):\n",
    "    p1, p2, p3, p4, p5 = X.shape\n",
    "    _, r1, r2, r3, r4, _ = ranks\n",
    "    factors = matrix_product_state(X, rank=ranks)\n",
    "    G1, G2, G3, G4, G5 = factors\n",
    "    G1 = G1.reshape(p1,r1,order=\"F\")\n",
    "    G5 = G5.reshape(r4,p5,order=\"F\")\n",
    "\n",
    "    G_ge2 = (tensordot(tensordot(tensordot(G2,G3,[2,0]),G4,[3,0]),G5,[4,0])).reshape(r1, p2*p3*p4*p5, order=\"F\")\n",
    "    A1 = (np.identity(p1)-G1@G1.T)@A.reshape(p1,p2*p3*p4*p5,order=\"F\")@G_ge2.T@np.linalg.inv(G_ge2@G_ge2.T)\n",
    "    delta_A1 = tensordot(tensordot(tensordot(tensordot(A1,G2,[1,0]),G3,[2,0]),G4,[3,0]),G5,[4,0])\n",
    "\n",
    "    G_ge3 = (tensordot(tensordot(G3,G4,[2,0]),G5,[3,0])).reshape(r2, p3*p4*p5, order=\"F\")\n",
    "    L_G2 = G2.reshape(p2*r1, r2, order=\"F\")\n",
    "    A2 = (np.identity(p2*r1)-L_G2@L_G2.T)@(np.kron(np.identity(p2), G1)).T@A.reshape(p1*p2,p3*p4*p5,order=\"F\")@G_ge3.T@np.linalg.inv(G_ge3@G_ge3.T)\n",
    "    delta_A2 = tensordot(tensordot(tensordot(tensordot(G1, A2.reshape([r1,p2,r2],order=\"F\"), [1, 0]), G3, [2, 0]), G4, [3, 0]), G5, [4,0])\n",
    "\n",
    "    G_ge4 = (tensordot(G4,G5,[2,0])).reshape(r3, p4*p5, order=\"F\")\n",
    "    L_G3 = G3.reshape(p3*r2, r3, order=\"F\")\n",
    "    G_le2 = (tensordot(G1,G2,[1,0])).reshape(p1*p2,r2, order=\"F\")\n",
    "    A3 = (np.identity(p3*r2)-L_G3@L_G3.T)@(np.kron(np.identity(p3), G_le2)).T@A.reshape(p1*p2*p3,p4*p5,order=\"F\")@G_ge4.T@np.linalg.inv(G_ge4@G_ge4.T)\n",
    "    delta_A3 = tensordot(tensordot(tensordot(tensordot(G1, G2, [1, 0]), A3.reshape([r2,p3,r3],order=\"F\"), [2, 0]), G4, [3, 0]), G5, [4,0])\n",
    "\n",
    "    L_G4 = G4.reshape(p4*r3, r4, order=\"F\")\n",
    "    G_le3 = (tensordot(tensordot(G1,G2,[1,0]),G3,[2,0])).reshape(p1*p2*p3,r3, order=\"F\")\n",
    "    A4 = (np.identity(p4*r3)-L_G4@L_G4.T)@(np.kron(np.identity(p4),G_le3)).T@A.reshape(p1*p2*p3*p4,p5,order=\"F\")@G5.T @np.linalg.inv(G5@G5.T)\n",
    "    delta_A4 = tensordot(tensordot(tensordot(tensordot(G1, G2, [1, 0]), G3, [2, 0]), A4.reshape([r3,p4,r4], order=\"F\"), [3, 0]),G5,[4,0])\n",
    "\n",
    "    G_le4 = (tensordot(tensordot(tensordot(G1,G2,[1,0]),G3,[2,0]),G4,[3,0])).reshape(p1*p2*p3*p4,r4,order=\"F\")\n",
    "    A5 = (np.kron(np.identity(p5), G_le4)).T@A.reshape(p1*p2*p3*p4*p5,1,order=\"F\")\n",
    "    delta_A5 = tensordot(tensordot(tensordot(tensordot(G1, G2, [1, 0]), G3, [2, 0]), G4,[3,0]),A5.reshape(r4,p5,order=\"F\"), [4, 0])\n",
    "\n",
    "    return delta_A1+delta_A2+delta_A3+delta_A4+delta_A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def PGD(Y, X, trueA, p_vec1, p_vec, mtl_rank, max_iter, tol):\n",
    "    p1, N = Y.shape\n",
    "    p, _ = X.shape\n",
    "    A_inittmp = (Y@X.T)/N\n",
    "    A_initts = TTOI(A_inittmp.reshape(p_vec1+p_vec,order=\"F\"),mtl_rank[1:-1],2,1e-4)[-1]\n",
    "    Amat = A_initts.reshape(p1,p,order=\"F\")\n",
    "    chg_list = [None] * max_iter\n",
    "    est_list = [None] * max_iter\n",
    "    n = 0\n",
    "    chg = np.inf\n",
    "    while n < max_iter and chg > tol:\n",
    "        start = time.time()\n",
    "        P = RGrad5(Amat.reshape(p_vec1+p_vec,order=\"F\"),mtl_rank,((Amat@X-Y)@X.T)/N)\n",
    "        Pmat = P.reshape(p1,p,order=\"F\")\n",
    "        eta = N*np.square(np.linalg.norm(Pmat,\"fro\"))/np.square(np.linalg.norm(Pmat@X,\"fro\"))\n",
    "        A_tmpmat = Amat - eta*Pmat\n",
    "        factors = matrix_product_state(A_tmpmat.reshape(p_vec1+p_vec,order=\"F\"), rank=mtl_rank)\n",
    "        A_newts = tt_to_tensor(factors)\n",
    "        A_newmat = A_newts.reshape(p1,p,order=\"F\")\n",
    "        chg_list[n] = np.linalg.norm(A_newmat-Amat, \"fro\")\n",
    "        est_list[n] = np.linalg.norm(A_newmat-trueA, \"fro\")\n",
    "        chg = np.linalg.norm(A_newmat-Amat, \"fro\")\n",
    "        if chg>10:\n",
    "            break\n",
    "        n=n+1\n",
    "        Amat = A_newmat\n",
    "        \n",
    "\n",
    "    return ([x for x in chg_list if x is not None],[x for x in est_list if x is not None],Amat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vec=[6,6,6]\n",
    "p = np.prod(p_vec)\n",
    "p_vec1=[6,6]\n",
    "p1 = np.prod(p_vec1)\n",
    "mtl_rank = [1,2,2,2,2,1]\n",
    "global G1; global G2; global G3; global sigma; global G4; global G5;\n",
    "global A_ts; global A_mat\n",
    "G1 = np.linalg.svd(np.random.normal(0,1,p_vec1[0]*p_vec1[0]).reshape(p_vec1[0],p_vec1[0]))[0][:,0:mtl_rank[1]].reshape(mtl_rank[0],p_vec1[0],mtl_rank[1],order=\"F\")\n",
    "G2 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec1[1]*mtl_rank[1])).reshape(p_vec1[1]*mtl_rank[1],p_vec1[1]*mtl_rank[1]))[0][:,0:mtl_rank[2]].reshape(mtl_rank[1],p_vec1[1],mtl_rank[2],order=\"F\")\n",
    "sigma = np.diag([3,3])\n",
    "G3 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[0]*mtl_rank[3])).reshape(p_vec[0]*mtl_rank[3],p_vec[0]*mtl_rank[3]))[2][0:mtl_rank[2],:].reshape(mtl_rank[2],p_vec[0],mtl_rank[3],order=\"F\")\n",
    "G4 = np.linalg.svd(np.random.normal(0,1,np.square(p_vec[1]*mtl_rank[4])).reshape(p_vec[1]*mtl_rank[4],p_vec[1]*mtl_rank[4]))[2][0:mtl_rank[3],:].reshape(mtl_rank[3],p_vec[1],mtl_rank[4],order=\"F\")\n",
    "G5 = np.linalg.svd(np.random.normal(0,1,p_vec[2]*p_vec[2]).reshape(p_vec[2],p_vec[2]))[2][0:mtl_rank[4],:].reshape(mtl_rank[4],p_vec[2],mtl_rank[5],order=\"F\")\n",
    "A_ts = (tensordot(tensordot(tensordot(tensordot(tensordot(G1,G2,[2,0]),sigma,[3,0]),G3,[3,0]),G4,[4,0]),G5,[5,0])).reshape(p_vec1+p_vec,order=\"F\")\n",
    "A_mat = A_ts.reshape(p1, p, order=\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('33sepr2.pkl','wb') as f:\n",
    "    pickle.dump([A_mat, A_ts], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('33sepr2.pkl','rb') as f:\n",
    "    A_mat, A_ts= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7469435305966434"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda1=np.linalg.svd(A_ts.reshape(6,36*36,order=\"F\"))[1][:2]\n",
    "lambda2=np.linalg.svd(A_ts.reshape(36,6*36,order=\"F\"))[1][:2]\n",
    "lambda3=np.linalg.svd(A_ts.reshape(216,36,order=\"F\"))[1][:2]\n",
    "lambda4=np.linalg.svd(A_ts.reshape(216*6,6,order=\"F\"))[1][:2]\n",
    "lambdatotal=np.concatenate((lambda1,lambda2,lambda3,lambda4))\n",
    "np.min(lambdatotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phi=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d1(ind):\n",
    "    torch.random.seed()\n",
    "    N=200\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    rmax = 3\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    result3 = []\n",
    "    result4 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in range(1,4):\n",
    "        result1a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i]+[rmax,rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result1a)\n",
    "        if result1a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result1a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result2a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax]+[i]+[rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result2.append(result2a)\n",
    "        if result2a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result2a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result3a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax]+[i]+[rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result3.append(result3a)\n",
    "        if result3a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result3a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result4a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax,rmax]+[i]+[1], max_iter=2000, tol=1e-4)\n",
    "        result4.append(result4a)\n",
    "        if result4a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result4a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "        \n",
    "        \n",
    "    rBIC1 = []\n",
    "    rsigma1 = []\n",
    "    rBIC2 = []\n",
    "    rsigma2 = []\n",
    "    rBIC3 = []\n",
    "    rsigma3 = []\n",
    "    rBIC4 = []\n",
    "    rsigma4 = []\n",
    "    for i in range(1,4):\n",
    "        sigma1 = (np.linalg.norm(Y-result1[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a1,b1,c1,d1 = (i,rmax,rmax,rmax)\n",
    "        df1 = 6*(a1+d1)+6*(a1*b1+b1*c1+c1*d1)+b1\n",
    "        BIC1 = np.log(sigma1)+0.1*np.log(Y.shape[1])*(df1+1)/(Y.shape[1])\n",
    "        rBIC1.append(BIC1)\n",
    "        rsigma1.append(np.log(sigma1))\n",
    "        \n",
    "        sigma2 = (np.linalg.norm(Y-result2[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a2,b2,c2,d2 = (rmax,i,rmax,rmax)\n",
    "        df2 = 6*(a2+d2)+6*(a2*b2+b2*c2+c2*d2)+b2\n",
    "        BIC2 = np.log(sigma2)+0.1*np.log(Y.shape[1])*(df2+1)/(Y.shape[1])\n",
    "        rBIC2.append(BIC2) \n",
    "        rsigma2.append(np.log(sigma2))\n",
    "        \n",
    "        sigma3 = (np.linalg.norm(Y-result3[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a3,b3,c3,d3 = (rmax,rmax,i,rmax)\n",
    "        df3 = 6*(a3+d3)+6*(a3*b3+b3*c3+c3*d3)+b3\n",
    "        BIC3 = np.log(sigma3)+0.1*np.log(Y.shape[1])*(df3+1)/(Y.shape[1])\n",
    "        rBIC3.append(BIC3) \n",
    "        rsigma3.append(np.log(sigma3))\n",
    "        \n",
    "        sigma4 = (np.linalg.norm(Y-result4[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a4,b4,c4,d4 = (rmax,rmax,rmax,i)\n",
    "        df4 = 6*(a4+d4)+6*(a4*b4+b4*c4+c4*d4)+b4\n",
    "        BIC4 = np.log(sigma4)+0.1*np.log(Y.shape[1])*(df4+1)/(Y.shape[1])\n",
    "        rBIC4.append(BIC4) \n",
    "        rsigma4.append(np.log(sigma4))\n",
    "\n",
    "        \n",
    "    est_rank = [np.argsort(np.array(rBIC1))[0]+1]+[np.argsort(np.array(rBIC2))[0]+1]+[np.argsort(np.array(rBIC3))[0]+1]+[np.argsort(np.array(rBIC4))[0]+1]\n",
    "    rBIC = rBIC1 + rBIC2 + rBIC3 +rBIC4\n",
    "    rsigma = rsigma1+rsigma2+rsigma3+rsigma4\n",
    "\n",
    "    return (rBIC,est_rank,t1,t2,rsigma,Y,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.197597569083376,\n",
       "  4.020846966721008,\n",
       "  4.079255081672327,\n",
       "  4.142443662745028,\n",
       "  3.993128040967061,\n",
       "  4.079255081672327,\n",
       "  4.115389427922744,\n",
       "  3.995165973057129,\n",
       "  4.079255081672327,\n",
       "  4.169893585468866,\n",
       "  4.022386946571959,\n",
       "  4.079255081672327],\n",
       " [2, 2, 2, 2],\n",
       " 0,\n",
       " 0,\n",
       " [3.7896271318591777,\n",
       "  3.5492967210982322,\n",
       "  3.5441250276509755,\n",
       "  3.803351351285954,\n",
       "  3.556016858226848,\n",
       "  3.5441250276509755,\n",
       "  3.7709987990971214,\n",
       "  3.555405631633642,\n",
       "  3.5441250276509755,\n",
       "  3.7619231482446676,\n",
       "  3.5508367009491835,\n",
       "  3.5441250276509755],\n",
       " array([[ 0.87545462,  1.00179456, -0.65576242, ..., -2.04852555,\n",
       "          2.44167732, -1.29406728],\n",
       "        [-0.98121127,  0.85018009,  1.86812105, ...,  1.22262802,\n",
       "         -0.14105227, -1.38111144],\n",
       "        [-1.06160401,  1.94244066,  1.56835292, ...,  1.51882326,\n",
       "         -0.09870425,  0.53008011],\n",
       "        ...,\n",
       "        [ 1.54404359,  0.01498013, -4.4694511 , ..., -1.80429003,\n",
       "          0.68443149, -2.3988765 ],\n",
       "        [ 1.40549912, -1.05373778,  0.19880696, ...,  0.08114938,\n",
       "         -0.11171209, -0.98975391],\n",
       "        [ 1.26610709, -0.61101501, -1.77233948, ...,  0.60945743,\n",
       "          0.09839005, -1.18799874]]),\n",
       " array([[ 0.0398129 , -0.24663942, -0.75989372, ..., -0.49990103,\n",
       "          0.01136855,  0.1760138 ],\n",
       "        [ 1.20833611, -0.14089216, -0.96708548, ...,  0.42399168,\n",
       "         -1.6737107 , -1.48235023],\n",
       "        [-2.29557157, -1.25889361, -0.24792573, ...,  1.28389406,\n",
       "         -0.03462391,  0.65036058],\n",
       "        ...,\n",
       "        [ 0.72347391, -0.77996927,  1.20404637, ..., -0.20189546,\n",
       "          0.29164657,  1.87381446],\n",
       "        [ 1.67579234,  0.71410048, -1.94559503, ..., -0.32337168,\n",
       "         -0.53076315,  1.18039405],\n",
       "        [-0.58804029,  0.41031978,  1.0634886 , ...,  1.02610993,\n",
       "          0.51540744, -0.76934332]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [10:01<00:00,  1.20s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603.0154409408569\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d1,l),total=500))\n",
    "        with open('N200.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2(ind):\n",
    "    torch.random.seed()\n",
    "    N=165\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    rmax = 3\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    result3 = []\n",
    "    result4 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in range(1,4):\n",
    "        result1a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i]+[rmax,rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result1a)\n",
    "        if result1a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result1a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result2a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax]+[i]+[rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result2.append(result2a)\n",
    "        if result2a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result2a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result3a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax]+[i]+[rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result3.append(result3a)\n",
    "        if result3a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result3a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result4a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax,rmax]+[i]+[1], max_iter=2000, tol=1e-4)\n",
    "        result4.append(result4a)\n",
    "        if result4a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result4a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "        \n",
    "        \n",
    "    rBIC1 = []\n",
    "    rsigma1 = []\n",
    "    rBIC2 = []\n",
    "    rsigma2 = []\n",
    "    rBIC3 = []\n",
    "    rsigma3 = []\n",
    "    rBIC4 = []\n",
    "    rsigma4 = []\n",
    "    for i in range(1,4):\n",
    "        sigma1 = (np.linalg.norm(Y-result1[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a1,b1,c1,d1 = (i,rmax,rmax,rmax)\n",
    "        df1 = 6*(a1+d1)+6*(a1*b1+b1*c1+c1*d1)+b1\n",
    "        BIC1 = np.log(sigma1)+0.02*np.log(Y.shape[1])*(df1+1)/(Y.shape[1])\n",
    "        rBIC1.append(BIC1)\n",
    "        rsigma1.append(np.log(sigma1))\n",
    "        \n",
    "        sigma2 = (np.linalg.norm(Y-result2[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a2,b2,c2,d2 = (rmax,i,rmax,rmax)\n",
    "        df2 = 6*(a2+d2)+6*(a2*b2+b2*c2+c2*d2)+b2\n",
    "        BIC2 = np.log(sigma2)+0.02*np.log(Y.shape[1])*(df2+1)/(Y.shape[1])\n",
    "        rBIC2.append(BIC2) \n",
    "        rsigma2.append(np.log(sigma2))\n",
    "        \n",
    "        sigma3 = (np.linalg.norm(Y-result3[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a3,b3,c3,d3 = (rmax,rmax,i,rmax)\n",
    "        df3 = 6*(a3+d3)+6*(a3*b3+b3*c3+c3*d3)+b3\n",
    "        BIC3 = np.log(sigma3)+0.02*np.log(Y.shape[1])*(df3+1)/(Y.shape[1])\n",
    "        rBIC3.append(BIC3) \n",
    "        rsigma3.append(np.log(sigma3))\n",
    "        \n",
    "        sigma4 = (np.linalg.norm(Y-result4[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a4,b4,c4,d4 = (rmax,rmax,rmax,i)\n",
    "        df4 = 6*(a4+d4)+6*(a4*b4+b4*c4+c4*d4)+b4\n",
    "        BIC4 = np.log(sigma4)+0.02*np.log(Y.shape[1])*(df4+1)/(Y.shape[1])\n",
    "        rBIC4.append(BIC4) \n",
    "        rsigma4.append(np.log(sigma4))\n",
    "\n",
    "        \n",
    "    est_rank = [np.argsort(np.array(rBIC1))[0]+1]+[np.argsort(np.array(rBIC2))[0]+1]+[np.argsort(np.array(rBIC3))[0]+1]+[np.argsort(np.array(rBIC4))[0]+1]\n",
    "    rBIC = rBIC1 + rBIC2 + rBIC3 +rBIC4\n",
    "    rsigma = rsigma1+rsigma2+rsigma3+rsigma4\n",
    "\n",
    "    return (rBIC,est_rank,t1,t2,rsigma,Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [11:04<00:00,  1.33s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665.4654319286346\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d2,l),total=500))\n",
    "        with open('N165.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d3(ind):\n",
    "    torch.random.seed()\n",
    "    N=130\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    rmax = 3\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    result3 = []\n",
    "    result4 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in range(1,4):\n",
    "        result1a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i]+[rmax,rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result1a)\n",
    "        if result1a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result1a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result2a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax]+[i]+[rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result2.append(result2a)\n",
    "        if result2a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result2a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result3a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax]+[i]+[rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result3.append(result3a)\n",
    "        if result3a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result3a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result4a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax,rmax]+[i]+[1], max_iter=2000, tol=1e-4)\n",
    "        result4.append(result4a)\n",
    "        if result4a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result4a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "        \n",
    "        \n",
    "    rBIC1 = []\n",
    "    rsigma1 = []\n",
    "    rBIC2 = []\n",
    "    rsigma2 = []\n",
    "    rBIC3 = []\n",
    "    rsigma3 = []\n",
    "    rBIC4 = []\n",
    "    rsigma4 = []\n",
    "    for i in range(1,4):\n",
    "        sigma1 = (np.linalg.norm(Y-result1[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a1,b1,c1,d1 = (i,rmax,rmax,rmax)\n",
    "        df1 = 6*(a1+d1)+6*(a1*b1+b1*c1+c1*d1)+b1\n",
    "        BIC1 = np.log(sigma1)+0.02*np.log(Y.shape[1])*(df1+1)/(Y.shape[1])\n",
    "        rBIC1.append(BIC1)\n",
    "        rsigma1.append(np.log(sigma1))\n",
    "        \n",
    "        sigma2 = (np.linalg.norm(Y-result2[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a2,b2,c2,d2 = (rmax,i,rmax,rmax)\n",
    "        df2 = 6*(a2+d2)+6*(a2*b2+b2*c2+c2*d2)+b2\n",
    "        BIC2 = np.log(sigma2)+0.02*np.log(Y.shape[1])*(df2+1)/(Y.shape[1])\n",
    "        rBIC2.append(BIC2) \n",
    "        rsigma2.append(np.log(sigma2))\n",
    "        \n",
    "        sigma3 = (np.linalg.norm(Y-result3[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a3,b3,c3,d3 = (rmax,rmax,i,rmax)\n",
    "        df3 = 6*(a3+d3)+6*(a3*b3+b3*c3+c3*d3)+b3\n",
    "        BIC3 = np.log(sigma3)+0.02*np.log(Y.shape[1])*(df3+1)/(Y.shape[1])\n",
    "        rBIC3.append(BIC3) \n",
    "        rsigma3.append(np.log(sigma3))\n",
    "        \n",
    "        sigma4 = (np.linalg.norm(Y-result4[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a4,b4,c4,d4 = (rmax,rmax,rmax,i)\n",
    "        df4 = 6*(a4+d4)+6*(a4*b4+b4*c4+c4*d4)+b4\n",
    "        BIC4 = np.log(sigma4)+0.02*np.log(Y.shape[1])*(df4+1)/(Y.shape[1])\n",
    "        rBIC4.append(BIC4) \n",
    "        rsigma4.append(np.log(sigma4))\n",
    "\n",
    "        \n",
    "    est_rank = [np.argsort(np.array(rBIC1))[0]+1]+[np.argsort(np.array(rBIC2))[0]+1]+[np.argsort(np.array(rBIC3))[0]+1]+[np.argsort(np.array(rBIC4))[0]+1]\n",
    "    rBIC = rBIC1 + rBIC2 + rBIC3 +rBIC4\n",
    "    rsigma = rsigma1+rsigma2+rsigma3+rsigma4\n",
    "\n",
    "    return (rBIC,est_rank,t1,t2,rsigma,Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [13:10<00:00,  1.58s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "791.5413143634796\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d3,l),total=500))\n",
    "        with open('N130.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d4(ind):\n",
    "    torch.random.seed()\n",
    "    N=95\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    rmax = 3\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    result3 = []\n",
    "    result4 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in range(1,4):\n",
    "        result1a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i]+[rmax,rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result1a)\n",
    "        if result1a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result1a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result2a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax]+[i]+[rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result2.append(result2a)\n",
    "        if result2a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result2a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result3a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax]+[i]+[rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result3.append(result3a)\n",
    "        if result3a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result3a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result4a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax,rmax]+[i]+[1], max_iter=2000, tol=1e-4)\n",
    "        result4.append(result4a)\n",
    "        if result4a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result4a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "        \n",
    "        \n",
    "    rBIC1 = []\n",
    "    rsigma1 = []\n",
    "    rBIC2 = []\n",
    "    rsigma2 = []\n",
    "    rBIC3 = []\n",
    "    rsigma3 = []\n",
    "    rBIC4 = []\n",
    "    rsigma4 = []\n",
    "    for i in range(1,4):\n",
    "        sigma1 = (np.linalg.norm(Y-result1[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a1,b1,c1,d1 = (i,rmax,rmax,rmax)\n",
    "        df1 = 6*(a1+d1)+6*(a1*b1+b1*c1+c1*d1)+b1\n",
    "        BIC1 = np.log(sigma1)+0.02*np.log(Y.shape[1])*(df1+1)/(Y.shape[1])\n",
    "        rBIC1.append(BIC1)\n",
    "        rsigma1.append(np.log(sigma1))\n",
    "        \n",
    "        sigma2 = (np.linalg.norm(Y-result2[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a2,b2,c2,d2 = (rmax,i,rmax,rmax)\n",
    "        df2 = 6*(a2+d2)+6*(a2*b2+b2*c2+c2*d2)+b2\n",
    "        BIC2 = np.log(sigma2)+0.02*np.log(Y.shape[1])*(df2+1)/(Y.shape[1])\n",
    "        rBIC2.append(BIC2) \n",
    "        rsigma2.append(np.log(sigma2))\n",
    "        \n",
    "        sigma3 = (np.linalg.norm(Y-result3[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a3,b3,c3,d3 = (rmax,rmax,i,rmax)\n",
    "        df3 = 6*(a3+d3)+6*(a3*b3+b3*c3+c3*d3)+b3\n",
    "        BIC3 = np.log(sigma3)+0.02*np.log(Y.shape[1])*(df3+1)/(Y.shape[1])\n",
    "        rBIC3.append(BIC3) \n",
    "        rsigma3.append(np.log(sigma3))\n",
    "        \n",
    "        sigma4 = (np.linalg.norm(Y-result4[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a4,b4,c4,d4 = (rmax,rmax,rmax,i)\n",
    "        df4 = 6*(a4+d4)+6*(a4*b4+b4*c4+c4*d4)+b4\n",
    "        BIC4 = np.log(sigma4)+0.02*np.log(Y.shape[1])*(df4+1)/(Y.shape[1])\n",
    "        rBIC4.append(BIC4) \n",
    "        rsigma4.append(np.log(sigma4))\n",
    "\n",
    "        \n",
    "    est_rank = [np.argsort(np.array(rBIC1))[0]+1]+[np.argsort(np.array(rBIC2))[0]+1]+[np.argsort(np.array(rBIC3))[0]+1]+[np.argsort(np.array(rBIC4))[0]+1]\n",
    "    rBIC = rBIC1 + rBIC2 + rBIC3 +rBIC4\n",
    "    rsigma = rsigma1+rsigma2+rsigma3+rsigma4\n",
    "\n",
    "    return (rBIC,est_rank,t1,t2,rsigma,Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [20:04<00:00,  2.41s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205.0489988327026\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d4,l),total=500))\n",
    "        with open('N95.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d5(ind):\n",
    "    torch.random.seed()\n",
    "    N=60\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    rmax = 3\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    result3 = []\n",
    "    result4 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in range(1,4):\n",
    "        result1a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i]+[rmax,rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result1a)\n",
    "        if result1a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result1a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result2a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax]+[i]+[rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result2.append(result2a)\n",
    "        if result2a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result2a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result3a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax]+[i]+[rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result3.append(result3a)\n",
    "        if result3a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result3a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result4a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax,rmax]+[i]+[1], max_iter=2000, tol=1e-4)\n",
    "        result4.append(result4a)\n",
    "        if result4a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result4a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "        \n",
    "        \n",
    "    rBIC1 = []\n",
    "    rsigma1 = []\n",
    "    rBIC2 = []\n",
    "    rsigma2 = []\n",
    "    rBIC3 = []\n",
    "    rsigma3 = []\n",
    "    rBIC4 = []\n",
    "    rsigma4 = []\n",
    "    for i in range(1,4):\n",
    "        sigma1 = (np.linalg.norm(Y-result1[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a1,b1,c1,d1 = (i,rmax,rmax,rmax)\n",
    "        df1 = 6*(a1+d1)+6*(a1*b1+b1*c1+c1*d1)+b1\n",
    "        BIC1 = np.log(sigma1)+0.02*np.log(Y.shape[1])*(df1+1)/(Y.shape[1])\n",
    "        rBIC1.append(BIC1)\n",
    "        rsigma1.append(np.log(sigma1))\n",
    "        \n",
    "        sigma2 = (np.linalg.norm(Y-result2[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a2,b2,c2,d2 = (rmax,i,rmax,rmax)\n",
    "        df2 = 6*(a2+d2)+6*(a2*b2+b2*c2+c2*d2)+b2\n",
    "        BIC2 = np.log(sigma2)+0.02*np.log(Y.shape[1])*(df2+1)/(Y.shape[1])\n",
    "        rBIC2.append(BIC2) \n",
    "        rsigma2.append(np.log(sigma2))\n",
    "        \n",
    "        sigma3 = (np.linalg.norm(Y-result3[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a3,b3,c3,d3 = (rmax,rmax,i,rmax)\n",
    "        df3 = 6*(a3+d3)+6*(a3*b3+b3*c3+c3*d3)+b3\n",
    "        BIC3 = np.log(sigma3)+0.02*np.log(Y.shape[1])*(df3+1)/(Y.shape[1])\n",
    "        rBIC3.append(BIC3) \n",
    "        rsigma3.append(np.log(sigma3))\n",
    "        \n",
    "        sigma4 = (np.linalg.norm(Y-result4[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a4,b4,c4,d4 = (rmax,rmax,rmax,i)\n",
    "        df4 = 6*(a4+d4)+6*(a4*b4+b4*c4+c4*d4)+b4\n",
    "        BIC4 = np.log(sigma4)+0.02*np.log(Y.shape[1])*(df4+1)/(Y.shape[1])\n",
    "        rBIC4.append(BIC4) \n",
    "        rsigma4.append(np.log(sigma4))\n",
    "\n",
    "        \n",
    "    est_rank = [np.argsort(np.array(rBIC1))[0]+1]+[np.argsort(np.array(rBIC2))[0]+1]+[np.argsort(np.array(rBIC3))[0]+1]+[np.argsort(np.array(rBIC4))[0]+1]\n",
    "    rBIC = rBIC1 + rBIC2 + rBIC3 +rBIC4\n",
    "    rsigma = rsigma1+rsigma2+rsigma3+rsigma4\n",
    "\n",
    "    return (rBIC,est_rank,t1,t2,rsigma,Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [41:34<00:00,  4.99s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494.844403743744\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d5,l),total=500))\n",
    "        with open('N60.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d6(ind):\n",
    "    torch.random.seed()\n",
    "    N=25\n",
    "    p_vec=[6,6,6]\n",
    "    p = np.prod(p_vec)\n",
    "    p_vec1=[6,6]\n",
    "    p1 = np.prod(p_vec1)\n",
    "    global X; global Y\n",
    "    X = torch.empty((p, N), dtype=torch.float64)\n",
    "    Y = torch.empty((p1, N), dtype=torch.float64)\n",
    "    for s in range(N):\n",
    "        X[:,s] = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p),covariance_matrix=torch.eye(p)).sample()\n",
    "        Y[:,s] = torch.tensor(A_mat) @ X[:,s] + torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros(p1),covariance_matrix=torch.eye(p1)).sample()\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "\n",
    "    rmax = 3\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    result3 = []\n",
    "    result4 = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for i in range(1,4):\n",
    "        result1a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1]+[i]+[rmax,rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result1.append(result1a)\n",
    "        if result1a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result1a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result2a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax]+[i]+[rmax,rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result2.append(result2a)\n",
    "        if result2a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result2a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result3a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax]+[i]+[rmax]+[1], max_iter=2000, tol=1e-4)\n",
    "        result3.append(result3a)\n",
    "        if result3a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result3a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "        \n",
    "        result4a = PGD(Y, X, trueA=A_mat, p_vec1=p_vec1, p_vec=p_vec, mtl_rank=[1,rmax,rmax,rmax]+[i]+[1], max_iter=2000, tol=1e-4)\n",
    "        result4.append(result4a)\n",
    "        if result4a[0][-1]>0.01:\n",
    "            t1 = t1 + 1\n",
    "        if len(result4a[1])>1998:\n",
    "            t2 = t2 + 1\n",
    "            \n",
    "        \n",
    "        \n",
    "    rBIC1 = []\n",
    "    rsigma1 = []\n",
    "    rBIC2 = []\n",
    "    rsigma2 = []\n",
    "    rBIC3 = []\n",
    "    rsigma3 = []\n",
    "    rBIC4 = []\n",
    "    rsigma4 = []\n",
    "    for i in range(1,4):\n",
    "        sigma1 = (np.linalg.norm(Y-result1[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a1,b1,c1,d1 = (i,rmax,rmax,rmax)\n",
    "        df1 = 6*(a1+d1)+6*(a1*b1+b1*c1+c1*d1)+b1\n",
    "        BIC1 = np.log(sigma1)+0.02*np.log(Y.shape[1])*(df1+1)/(Y.shape[1])\n",
    "        rBIC1.append(BIC1)\n",
    "        rsigma1.append(np.log(sigma1))\n",
    "        \n",
    "        sigma2 = (np.linalg.norm(Y-result2[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a2,b2,c2,d2 = (rmax,i,rmax,rmax)\n",
    "        df2 = 6*(a2+d2)+6*(a2*b2+b2*c2+c2*d2)+b2\n",
    "        BIC2 = np.log(sigma2)+0.02*np.log(Y.shape[1])*(df2+1)/(Y.shape[1])\n",
    "        rBIC2.append(BIC2) \n",
    "        rsigma2.append(np.log(sigma2))\n",
    "        \n",
    "        sigma3 = (np.linalg.norm(Y-result3[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a3,b3,c3,d3 = (rmax,rmax,i,rmax)\n",
    "        df3 = 6*(a3+d3)+6*(a3*b3+b3*c3+c3*d3)+b3\n",
    "        BIC3 = np.log(sigma3)+0.02*np.log(Y.shape[1])*(df3+1)/(Y.shape[1])\n",
    "        rBIC3.append(BIC3) \n",
    "        rsigma3.append(np.log(sigma3))\n",
    "        \n",
    "        sigma4 = (np.linalg.norm(Y-result4[i-1][2]@X)**2)/(Y.shape[1])\n",
    "        a4,b4,c4,d4 = (rmax,rmax,rmax,i)\n",
    "        df4 = 6*(a4+d4)+6*(a4*b4+b4*c4+c4*d4)+b4\n",
    "        BIC4 = np.log(sigma4)+0.02*np.log(Y.shape[1])*(df4+1)/(Y.shape[1])\n",
    "        rBIC4.append(BIC4) \n",
    "        rsigma4.append(np.log(sigma4))\n",
    "\n",
    "        \n",
    "    est_rank = [np.argsort(np.array(rBIC1))[0]+1]+[np.argsort(np.array(rBIC2))[0]+1]+[np.argsort(np.array(rBIC3))[0]+1]+[np.argsort(np.array(rBIC4))[0]+1]\n",
    "    rBIC = rBIC1 + rBIC2 + rBIC3 +rBIC4\n",
    "    rsigma = rsigma1+rsigma2+rsigma3+rsigma4\n",
    "\n",
    "    return (rBIC,est_rank,t1,t2,rsigma,Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [40:22<00:00,  4.85s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2423.4603595733643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "if __name__ == '__main__':\n",
    "    l = list(range(500))\n",
    "    with Pool(40) as p:\n",
    "        result = list(tqdm.tqdm(p.imap(d6,l),total=500))\n",
    "        with open('N25.pkl','wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('N200.pkl','rb') as f:\n",
    "    result = pickle.load(f)\n",
    "list1 = []\n",
    "a1 = 0\n",
    "t1 = []\n",
    "a2 = 0\n",
    "t2 = []\n",
    "a3 = 0\n",
    "total = 0\n",
    "for i in range(len(result)):\n",
    "    total+=1\n",
    "    list1.append(result[i][1])\n",
    "    if result[i][1]==[2,2,2,2]:\n",
    "        a1 = a1 + 1\n",
    "    t1.append(result[i][2])\n",
    "    if result[i][2]>0:\n",
    "        a2 = a2 + 1\n",
    "    t2.append(result[i][3])\n",
    "    if result[i][3]>0:\n",
    "        a3 = a3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(a1)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
